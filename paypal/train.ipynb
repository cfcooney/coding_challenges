{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a21ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple Random Forest Model - Train and Predict\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_percentage_error, r2_score, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3207c294",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleRandomForestPredictor:\n",
    "    \"\"\"\n",
    "    Minimal Random Forest predictor for training and prediction with optional log transformation\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, n_estimators=100, max_depth=10, random_state=42, use_log_transform=True):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_depth = max_depth\n",
    "        self.random_state = random_state\n",
    "        self.use_log_transform = use_log_transform\n",
    "        self.pipeline = None\n",
    "        \n",
    "    def fit(self, X_train, y_train):\n",
    "        \"\"\"\n",
    "        Train the model on full training set with optional log transformation\n",
    "        \"\"\"\n",
    "        print(\"ðŸŒ² Training Random Forest model...\")\n",
    "        \n",
    "        # Apply log transformation to target if enabled\n",
    "        if self.use_log_transform:\n",
    "            print(\"   âœ… Applying log1p transformation to target variable\")\n",
    "            y_train_transformed = np.log1p(y_train.copy())\n",
    "            print(f\"   Target range after log1p: [{y_train_transformed.min():.4f}, {y_train_transformed.max():.4f}]\")\n",
    "        else:\n",
    "            y_train_transformed = y_train.copy()\n",
    "        \n",
    "        # Identify column types\n",
    "        numerical_cols = X_train.select_dtypes(include=[np.number]).columns.tolist()\n",
    "        categorical_cols = X_train.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "        \n",
    "        print(f\"Numerical features: {numerical_cols}\")\n",
    "        print(f\"Categorical features: {categorical_cols}\")\n",
    "        \n",
    "        # Create preprocessing pipeline\n",
    "        preprocessor = ColumnTransformer(\n",
    "            transformers=[\n",
    "                ('num', StandardScaler(), numerical_cols),\n",
    "                ('cat', OneHotEncoder(drop='first', sparse_output=False), categorical_cols)\n",
    "            ])\n",
    "        \n",
    "        # Create full pipeline\n",
    "        self.pipeline = Pipeline([\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('regressor', RandomForestRegressor(\n",
    "                n_estimators=self.n_estimators,\n",
    "                max_depth=self.max_depth,\n",
    "                random_state=self.random_state,\n",
    "                n_jobs=-1\n",
    "            ))\n",
    "        ])\n",
    "        \n",
    "        # Fit the model on transformed target\n",
    "        self.pipeline.fit(X_train, y_train_transformed)\n",
    "        print(\"âœ… Model training completed!\")\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        \"\"\"\n",
    "        Make predictions on test set with inverse transformation if log was used\n",
    "        \"\"\"\n",
    "        if self.pipeline is None:\n",
    "            raise ValueError(\"Model not trained yet! Call fit() first.\")\n",
    "        \n",
    "        # Get predictions in log space\n",
    "        log_predictions = self.pipeline.predict(X_test)\n",
    "        \n",
    "        # Apply inverse transformation if log transform was used\n",
    "        if self.use_log_transform:\n",
    "            predictions = np.expm1(log_predictions)\n",
    "            print(\"   âœ… Applied expm1 inverse transformation to predictions\")\n",
    "        else:\n",
    "            predictions = log_predictions\n",
    "            \n",
    "        return predictions\n",
    "    \n",
    "    def evaluate(self, X_test, y_test):\n",
    "        \"\"\"\n",
    "        Evaluate model performance on test set with proper inverse transformation\n",
    "        \"\"\"\n",
    "        predictions = self.predict(X_test)\n",
    "        \n",
    "        # Calculate metrics on original scale\n",
    "        mape = mean_absolute_percentage_error(y_test, predictions) * 100\n",
    "        r2 = r2_score(y_test, predictions)\n",
    "        rmse = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "        \n",
    "        print(f\"Test Set Performance (Original Scale):\")\n",
    "        print(f\"MAPE: {mape:.2f}%\")\n",
    "        print(f\"RÂ² Score: {r2:.4f}\")\n",
    "        print(f\"RMSE: {rmse:.2f}\")\n",
    "        \n",
    "        return {\n",
    "            'mape': mape,\n",
    "            'r2': r2,\n",
    "            'rmse': rmse,\n",
    "            'predictions': predictions\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22770fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage with log transformation:\n",
    "# \n",
    "# # Load your data\n",
    "# train_df = pd.read_csv('train_data.csv')\n",
    "# test_df = pd.read_csv('test_data.csv')\n",
    "# \n",
    "# # Prepare features and target\n",
    "# target_column = 'estimated_loss'  # Replace with your target column name\n",
    "# X_train = train_df.drop(columns=[target_column])\n",
    "# y_train = train_df[target_column]\n",
    "# X_test = test_df.drop(columns=[target_column]) if target_column in test_df.columns else test_df\n",
    "# y_test = test_df[target_column] if target_column in test_df.columns else None\n",
    "# \n",
    "# # Train model with log transformation (default)\n",
    "# model = SimpleRandomForestPredictor(n_estimators=100, max_depth=10, random_state=42, use_log_transform=True)\n",
    "# model.fit(X_train, y_train)\n",
    "# \n",
    "# # Make predictions (automatically applies inverse transform: expm1)\n",
    "# predictions = model.predict(X_test)\n",
    "# \n",
    "# # If you have test labels, evaluate performance\n",
    "# if y_test is not None:\n",
    "#     results = model.evaluate(X_test, y_test)\n",
    "#     print(f\"Predictions shape: {predictions.shape}\")\n",
    "# else:\n",
    "#     print(f\"Predictions: {predictions[:5]}...\")  # Show first 5 predictions\n",
    "# \n",
    "# # Note: Predictions are now in original scale (inverse transformed)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
