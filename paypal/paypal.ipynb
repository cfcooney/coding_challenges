{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b4cb9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced Random Forest Predictor with Log Transformation\n",
    "class LogTransformRandomForestPredictor(RandomForestLossPredictor):\n",
    "    \"\"\"\n",
    "    Enhanced Random Forest predictor with log transformation for target variable\n",
    "    - Applies np.log1p() to target during training\n",
    "    - Applies np.expm1() to predictions to reverse the transformation\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, n_estimators=100, max_depth=10, random_state=42, use_log_transform=True):\n",
    "        super().__init__(n_estimators, max_depth, random_state)\n",
    "        self.use_log_transform = use_log_transform\n",
    "        \n",
    "    def prepare_data(self, df, target_col, test_size=0.2):\n",
    "        \"\"\"\n",
    "        Prepare data with optional log transformation of target\n",
    "        \"\"\"\n",
    "        print(\"üîÑ Preparing data with log transformation...\")\n",
    "        \n",
    "        # Separate features and target\n",
    "        X = df.drop(columns=[target_col])\n",
    "        y = df[target_col].copy()\n",
    "        \n",
    "        # Apply log transformation to target if enabled\n",
    "        if self.use_log_transform:\n",
    "            print(\"   ‚úÖ Applying log1p transformation to target variable\")\n",
    "            # Add small constant to handle zeros, then apply log1p\n",
    "            y = np.log1p(y)\n",
    "            print(f\"   Target range after log1p: [{y.min():.4f}, {y.max():.4f}]\")\n",
    "        \n",
    "        # Identify column types\n",
    "        numerical_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "        categorical_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "        \n",
    "        print(f\"Numerical features ({len(numerical_cols)}): {numerical_cols}\")\n",
    "        print(f\"Categorical features ({len(categorical_cols)}): {categorical_cols}\")\n",
    "        \n",
    "        # Create preprocessing pipeline\n",
    "        preprocessor = ColumnTransformer(\n",
    "            transformers=[\n",
    "                ('num', StandardScaler(), numerical_cols),\n",
    "                ('cat', OneHotEncoder(drop='first', sparse_output=False), categorical_cols)\n",
    "            ])\n",
    "        \n",
    "        # Split data\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=test_size, random_state=self.random_state\n",
    "        )\n",
    "        \n",
    "        print(f\"Training set: {X_train.shape[0]} samples\")\n",
    "        print(f\"Test set: {X_test.shape[0]} samples\")\n",
    "        \n",
    "        # Store for later use\n",
    "        self.X_train = X_train\n",
    "        self.X_test = X_test\n",
    "        self.y_train = y_train\n",
    "        self.y_test = y_test\n",
    "        self.preprocessor = preprocessor\n",
    "        self.numerical_cols = numerical_cols\n",
    "        self.categorical_cols = categorical_cols\n",
    "        \n",
    "        return X_train, X_test, y_train, y_test\n",
    "    \n",
    "    def predict(self, new_data):\n",
    "        \"\"\"\n",
    "        Make predictions on new data with inverse log transformation\n",
    "        \"\"\"\n",
    "        if self.pipeline is None:\n",
    "            raise ValueError(\"Model not trained yet! Call train_model() first.\")\n",
    "        \n",
    "        # Get predictions from the model (in log space)\n",
    "        log_predictions = self.pipeline.predict(new_data)\n",
    "        \n",
    "        # Apply inverse transformation if log transform was used\n",
    "        if self.use_log_transform:\n",
    "            # Apply expm1 to reverse the log1p transformation\n",
    "            predictions = np.expm1(log_predictions)\n",
    "            print(\"   ‚úÖ Applied expm1 inverse transformation to predictions\")\n",
    "        else:\n",
    "            predictions = log_predictions\n",
    "            \n",
    "        return predictions\n",
    "    \n",
    "    def evaluate_model(self):\n",
    "        \"\"\"\n",
    "        Evaluate model with proper inverse transformation for MAPE calculation\n",
    "        \"\"\"\n",
    "        print(\"üìä Evaluating model performance with inverse transformation...\")\n",
    "        \n",
    "        # Get predictions in log space\n",
    "        log_predictions = self.pipeline.predict(self.X_test)\n",
    "        \n",
    "        # Apply inverse transformation to get predictions in original scale\n",
    "        if self.use_log_transform:\n",
    "            y_pred = np.expm1(log_predictions)\n",
    "            y_test_original = np.expm1(self.y_test)  # Convert test set back to original scale\n",
    "            print(\"   ‚úÖ Applied expm1 inverse transformation for evaluation\")\n",
    "        else:\n",
    "            y_pred = log_predictions\n",
    "            y_test_original = self.y_test\n",
    "        \n",
    "        # Calculate MAPE on original scale\n",
    "        mape = mean_absolute_percentage_error(y_test_original, y_pred) * 100\n",
    "        \n",
    "        # Calculate other metrics on original scale\n",
    "        r2 = r2_score(y_test_original, y_pred)\n",
    "        mse = mean_squared_error(y_test_original, y_pred)\n",
    "        rmse = np.sqrt(mse)\n",
    "        mae = mean_absolute_error(y_test_original, y_pred)\n",
    "        \n",
    "        print(f\"Test Set Performance (Original Scale):\")\n",
    "        print(f\"MAPE: {mape:.4f}% üéØ (Primary Metric)\")\n",
    "        print(f\"R¬≤ Score: {r2:.4f}\")\n",
    "        print(f\"RMSE: {rmse:.2f}\")\n",
    "        print(f\"MAE: {mae:.2f}\")\n",
    "        \n",
    "        # MAPE interpretation\n",
    "        if mape < 10:\n",
    "            print(\"üìà Excellent prediction accuracy (MAPE < 10%)\")\n",
    "        elif mape < 20:\n",
    "            print(\"üìä Good prediction accuracy (MAPE < 20%)\")\n",
    "        elif mape < 50:\n",
    "            print(\"‚ö†Ô∏è Reasonable prediction accuracy (MAPE < 50%)\")\n",
    "        else:\n",
    "            print(\"‚ùå Poor prediction accuracy (MAPE > 50%)\")\n",
    "        \n",
    "        # Also evaluate in log space for comparison\n",
    "        if self.use_log_transform:\n",
    "            log_r2 = r2_score(self.y_test, log_predictions)\n",
    "            log_mse = mean_squared_error(self.y_test, log_predictions)\n",
    "            print(f\"\\nLog Space Performance (for reference):\")\n",
    "            print(f\"Log R¬≤ Score: {log_r2:.4f}\")\n",
    "            print(f\"Log MSE: {log_mse:.4f}\")\n",
    "        \n",
    "        return {\n",
    "            'mape': mape,\n",
    "            'r2': r2,\n",
    "            'rmse': rmse,\n",
    "            'mae': mae,\n",
    "            'predictions': y_pred,\n",
    "            'y_test_original': y_test_original\n",
    "        }\n",
    "\n",
    "print(\"‚úÖ LogTransformRandomForestPredictor class created!\")\n",
    "print(\"üìù Key features:\")\n",
    "print(\"  - Automatically applies np.log1p() to target during training\")\n",
    "print(\"  - Automatically applies np.expm1() to predictions\")\n",
    "print(\"  - Evaluates MAPE on original scale for meaningful results\")\n",
    "print(\"  - Handles zero values gracefully with log1p/expm1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21615c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstration: Using Log Transform Predictor\n",
    "print(\"üéØ TESTING LOG TRANSFORM RANDOM FOREST PREDICTOR\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Create log-transform predictor\n",
    "log_rf_predictor = LogTransformRandomForestPredictor(\n",
    "    n_estimators=100,\n",
    "    max_depth=10,\n",
    "    random_state=42,\n",
    "    use_log_transform=True  # Enable log transformation\n",
    ")\n",
    "\n",
    "print(\"\\n1Ô∏è‚É£ Data Preparation with Log Transform\")\n",
    "X_train_log, X_test_log, y_train_log, y_test_log = log_rf_predictor.prepare_data(\n",
    "    df_ml, 'estimated_loss', test_size=0.2\n",
    ")\n",
    "\n",
    "print(\"\\n2Ô∏è‚É£ Model Training (on log-transformed target)\")\n",
    "cv_scores = log_rf_predictor.train_model(cv_folds=5)\n",
    "\n",
    "print(\"\\n3Ô∏è‚É£ Model Evaluation (with automatic inverse transformation)\")\n",
    "results = log_rf_predictor.evaluate_model()\n",
    "\n",
    "print(\"\\n4Ô∏è‚É£ Feature Importance Analysis\")\n",
    "log_rf_predictor.plot_feature_importance(top_n=12)\n",
    "\n",
    "print(\"\\n5Ô∏è‚É£ Test Predictions with Inverse Transform\")\n",
    "# Test with some sample data\n",
    "test_sample = df_ml.drop(columns=['estimated_loss']).head(5)\n",
    "predictions = log_rf_predictor.predict(test_sample)\n",
    "\n",
    "print(\"Sample predictions (automatically inverse-transformed):\")\n",
    "original_values = df_ml['estimated_loss'].head(5).values\n",
    "for i, (pred, actual) in enumerate(zip(predictions, original_values)):\n",
    "    error_pct = abs(pred - actual) / actual * 100 if actual > 0 else 0\n",
    "    print(f\"  Sample {i+1}: Predicted=${pred:.2f}, Actual=${actual:.2f}, Error={error_pct:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36f4d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparison: Log Transform vs Regular Predictor\n",
    "print(\"‚öñÔ∏è COMPARING LOG TRANSFORM vs REGULAR PREDICTOR\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Test both approaches\n",
    "print(\"\\nüîÑ Testing Regular Predictor (no log transform)...\")\n",
    "regular_predictor = LogTransformRandomForestPredictor(\n",
    "    n_estimators=100,\n",
    "    max_depth=10,\n",
    "    random_state=42,\n",
    "    use_log_transform=False  # Disable log transformation\n",
    ")\n",
    "\n",
    "# Train regular predictor\n",
    "regular_predictor.prepare_data(df_ml, 'estimated_loss', test_size=0.2)\n",
    "regular_predictor.train_model(cv_folds=3)\n",
    "regular_results = regular_predictor.evaluate_model()\n",
    "\n",
    "print(\"\\nüîÑ Testing Log Transform Predictor...\")\n",
    "log_predictor = LogTransformRandomForestPredictor(\n",
    "    n_estimators=100,\n",
    "    max_depth=10,\n",
    "    random_state=42,\n",
    "    use_log_transform=True  # Enable log transformation\n",
    ")\n",
    "\n",
    "# Train log predictor  \n",
    "log_predictor.prepare_data(df_ml, 'estimated_loss', test_size=0.2)\n",
    "log_predictor.train_model(cv_folds=3)\n",
    "log_results = log_predictor.evaluate_model()\n",
    "\n",
    "print(\"\\nüìä COMPARISON RESULTS\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"{'Metric':<15} {'Regular':<12} {'Log Transform':<15} {'Improvement'}\")\n",
    "print(\"-\" * 55)\n",
    "\n",
    "metrics = ['mape', 'r2', 'rmse', 'mae']\n",
    "for metric in metrics:\n",
    "    regular_val = regular_results[metric]\n",
    "    log_val = log_results[metric]\n",
    "    \n",
    "    # Calculate improvement (for MAPE and RMSE, lower is better)\n",
    "    if metric in ['mape', 'rmse', 'mae']:\n",
    "        improvement = ((regular_val - log_val) / regular_val) * 100\n",
    "        improvement_str = f\"{improvement:+.1f}%\" if improvement != 0 else \"0.0%\"\n",
    "    else:  # For R2, higher is better\n",
    "        improvement = ((log_val - regular_val) / regular_val) * 100 if regular_val != 0 else 0\n",
    "        improvement_str = f\"{improvement:+.1f}%\" if improvement != 0 else \"0.0%\"\n",
    "    \n",
    "    print(f\"{metric.upper():<15} {regular_val:<12.3f} {log_val:<15.3f} {improvement_str}\")\n",
    "\n",
    "print(\"\\nüí° LOG TRANSFORMATION BENEFITS:\")\n",
    "print(\"‚úÖ Reduces impact of outliers\")\n",
    "print(\"‚úÖ Handles skewed target distributions better\") \n",
    "print(\"‚úÖ Often improves prediction of small values\")\n",
    "print(\"‚úÖ Can reduce heteroscedasticity (non-constant variance)\")\n",
    "print(\"‚úÖ Makes multiplicative relationships additive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28180b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick Guide: Applying Log Transform to Existing Models\n",
    "print(\"üìù QUICK GUIDE: ADDING LOG TRANSFORM TO EXISTING MODELS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\"\"\n",
    "üîÑ STEP-BY-STEP PROCESS:\n",
    "\n",
    "1Ô∏è‚É£ PREPARE TARGET WITH LOG TRANSFORM:\n",
    "   # During data preparation\n",
    "   y_original = df['estimated_loss']\n",
    "   y_log = np.log1p(y_original)  # Use log1p to handle zeros\n",
    "   \n",
    "2Ô∏è‚É£ TRAIN MODEL ON LOG-TRANSFORMED TARGET:\n",
    "   # Train your model using y_log instead of y_original\n",
    "   model.fit(X_train, y_log_train)\n",
    "   \n",
    "3Ô∏è‚É£ INVERSE TRANSFORM PREDICTIONS:\n",
    "   # After getting predictions\n",
    "   log_predictions = model.predict(X_test)\n",
    "   final_predictions = np.expm1(log_predictions)  # Inverse transform\n",
    "   \n",
    "4Ô∏è‚É£ EVALUATE ON ORIGINAL SCALE:\n",
    "   # Calculate MAPE on original scale\n",
    "   y_test_original = np.expm1(y_log_test)  # Convert test back to original\n",
    "   mape = mean_absolute_percentage_error(y_test_original, final_predictions)\n",
    "\n",
    "üí° KEY POINTS:\n",
    "‚úÖ Always use log1p/expm1 pair (handles zeros gracefully)\n",
    "‚úÖ Train on log-transformed target\n",
    "‚úÖ Apply expm1 to ALL predictions before evaluation\n",
    "‚úÖ Evaluate metrics on original scale for meaningful interpretation\n",
    "‚úÖ Log transformation often helps with skewed financial data\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\nüõ†Ô∏è UTILITY FUNCTIONS:\")\n",
    "\n",
    "def apply_log_transform_to_target(y):\n",
    "    \"\"\"Apply log1p transformation to target variable\"\"\"\n",
    "    return np.log1p(y)\n",
    "\n",
    "def inverse_log_transform_predictions(log_predictions):\n",
    "    \"\"\"Apply expm1 to inverse log transformation\"\"\"\n",
    "    return np.expm1(log_predictions)\n",
    "\n",
    "def evaluate_with_log_inverse(model, X_test, y_test_log, y_test_original=None):\n",
    "    \"\"\"Evaluate model with automatic log inverse transformation\"\"\"\n",
    "    # Get predictions in log space\n",
    "    log_pred = model.predict(X_test)\n",
    "    \n",
    "    # Transform back to original scale\n",
    "    pred_original = inverse_log_transform_predictions(log_pred)\n",
    "    \n",
    "    # If original test values not provided, compute them\n",
    "    if y_test_original is None:\n",
    "        y_test_original = inverse_log_transform_predictions(y_test_log)\n",
    "    \n",
    "    # Calculate metrics on original scale\n",
    "    mape = mean_absolute_percentage_error(y_test_original, pred_original) * 100\n",
    "    r2 = r2_score(y_test_original, pred_original)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test_original, pred_original))\n",
    "    \n",
    "    return {\n",
    "        'mape': mape,\n",
    "        'r2': r2, \n",
    "        'rmse': rmse,\n",
    "        'predictions_original': pred_original,\n",
    "        'predictions_log': log_pred\n",
    "    }\n",
    "\n",
    "print(\"‚úÖ Utility functions defined!\")\n",
    "print(\"   - apply_log_transform_to_target()\")\n",
    "print(\"   - inverse_log_transform_predictions()\")\n",
    "print(\"   - evaluate_with_log_inverse()\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eedfb94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style for better visualizations\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8ec05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill NaN values with 0 for all numerical columns\n",
    "df = df.fillna(0)\n",
    "print(\"NaN values filled with 0\")\n",
    "print(f\"Dataset shape after filling: {df.shape}\")\n",
    "print(f\"Remaining NaN values: {df.isnull().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb91a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample dataset for demonstration\n",
    "np.random.seed(42)\n",
    "n_samples = 1000\n",
    "\n",
    "# Generate correlated features with different strength relationships\n",
    "data = {\n",
    "    'feature_1': np.random.normal(0, 1, n_samples),\n",
    "    'feature_2': np.random.normal(0, 1, n_samples),\n",
    "    'feature_3': np.random.normal(0, 1, n_samples),\n",
    "    'feature_4': np.random.exponential(2, n_samples),\n",
    "    'feature_5': np.random.uniform(-5, 5, n_samples)\n",
    "}\n",
    "\n",
    "# Create target variable with different relationships to features\n",
    "target = (2 * data['feature_1'] + \n",
    "         0.5 * data['feature_2'] + \n",
    "         -1.5 * data['feature_3'] + \n",
    "         0.1 * data['feature_4'] + \n",
    "         0.05 * data['feature_5'] + \n",
    "         np.random.normal(0, 0.5, n_samples))\n",
    "\n",
    "data['target'] = target\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(\"Sample dataset created:\")\n",
    "print(df.head())\n",
    "print(f\"\\nDataset shape: {df.shape}\")\n",
    "print(f\"\\nData types:\\n{df.dtypes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d775a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_numerical_relationships(df, target_col, exclude_cols=None):\n",
    "    \"\"\"\n",
    "    Comprehensive analysis of relationships between numerical columns and target variable\n",
    "    \n",
    "    Parameters:\n",
    "    df: pandas DataFrame\n",
    "    target_col: string, name of target column\n",
    "    exclude_cols: list, columns to exclude from analysis\n",
    "    \"\"\"\n",
    "    \n",
    "    if exclude_cols is None:\n",
    "        exclude_cols = []\n",
    "    \n",
    "    # Select only numerical columns\n",
    "    numerical_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    \n",
    "    # Remove target column and excluded columns\n",
    "    feature_cols = [col for col in numerical_cols if col != target_col and col not in exclude_cols]\n",
    "    \n",
    "    print(f\"Analyzing relationships between {len(feature_cols)} numerical features and target '{target_col}'\")\n",
    "    print(f\"Features: {feature_cols}\")\n",
    "    \n",
    "    return feature_cols\n",
    "\n",
    "# Example usage\n",
    "target_column = 'target'\n",
    "feature_columns = analyze_numerical_relationships(df, target_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e2d0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. CORRELATION ANALYSIS\n",
    "def correlation_analysis(df, target_col, feature_cols):\n",
    "    \"\"\"Calculate and display correlation coefficients\"\"\"\n",
    "    \n",
    "    correlations = []\n",
    "    \n",
    "    for col in feature_cols:\n",
    "        # Pearson correlation (linear relationships)\n",
    "        pearson_corr, pearson_p = pearsonr(df[col], df[target_col])\n",
    "        \n",
    "        # Spearman correlation (monotonic relationships)\n",
    "        spearman_corr, spearman_p = spearmanr(df[col], df[target_col])\n",
    "        \n",
    "        correlations.append({\n",
    "            'Feature': col,\n",
    "            'Pearson_Correlation': pearson_corr,\n",
    "            'Pearson_p_value': pearson_p,\n",
    "            'Spearman_Correlation': spearman_corr,\n",
    "            'Spearman_p_value': spearman_p,\n",
    "            'Abs_Pearson': abs(pearson_corr)\n",
    "        })\n",
    "    \n",
    "    corr_df = pd.DataFrame(correlations)\n",
    "    corr_df = corr_df.sort_values('Abs_Pearson', ascending=False)\n",
    "    \n",
    "    print(\"CORRELATION ANALYSIS:\")\n",
    "    print(\"=\" * 50)\n",
    "    print(corr_df.round(4))\n",
    "    \n",
    "    return corr_df\n",
    "\n",
    "# Run correlation analysis\n",
    "correlation_results = correlation_analysis(df, target_column, feature_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff769ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. CORRELATION HEATMAP\n",
    "def plot_correlation_heatmap(df, target_col, feature_cols):\n",
    "    \"\"\"Create correlation heatmap\"\"\"\n",
    "    \n",
    "    # Create correlation matrix\n",
    "    cols_to_plot = feature_cols + [target_col]\n",
    "    correlation_matrix = df[cols_to_plot].corr()\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    \n",
    "    # Create heatmap\n",
    "    mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))\n",
    "    sns.heatmap(correlation_matrix, \n",
    "                mask=mask,\n",
    "                annot=True, \n",
    "                cmap='RdBu_r', \n",
    "                center=0,\n",
    "                square=True,\n",
    "                fmt='.3f',\n",
    "                cbar_kws={\"shrink\": .8})\n",
    "    \n",
    "    plt.title(f'Correlation Matrix: Features vs {target_col}', fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_correlation_heatmap(df, target_column, feature_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5db9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. SCATTER PLOTS WITH REGRESSION LINES\n",
    "def plot_scatter_relationships(df, target_col, feature_cols, cols_per_row=3, remove_outliers=True, outlier_threshold=3):\n",
    "    \"\"\"Create scatter plots for each feature vs target\"\"\"\n",
    "    \n",
    "    n_features = len(feature_cols)\n",
    "    n_rows = (n_features + cols_per_row - 1) // cols_per_row\n",
    "    \n",
    "    fig, axes = plt.subplots(n_rows, cols_per_row, figsize=(15, 5*n_rows))\n",
    "    \n",
    "    # Flatten axes array for easier indexing\n",
    "    if n_rows == 1:\n",
    "        axes = [axes] if cols_per_row == 1 else axes\n",
    "    else:\n",
    "        axes = axes.flatten()\n",
    "    \n",
    "    for i, col in enumerate(feature_cols):\n",
    "        ax = axes[i]\n",
    "        \n",
    "        # Create a copy of data for outlier removal\n",
    "        df_plot = df[[col, target_col]].copy()\n",
    "        \n",
    "        if remove_outliers:\n",
    "            # Remove outliers using z-score method\n",
    "            z_scores_col = np.abs((df_plot[col] - df_plot[col].mean()) / df_plot[col].std())\n",
    "            z_scores_target = np.abs((df_plot[target_col] - df_plot[target_col].mean()) / df_plot[target_col].std())\n",
    "            \n",
    "            # Keep points where both feature and target are within threshold\n",
    "            mask = (z_scores_col < outlier_threshold) & (z_scores_target < outlier_threshold)\n",
    "            df_plot = df_plot[mask]\n",
    "            \n",
    "            outliers_removed = len(df) - len(df_plot)\n",
    "            if outliers_removed > 0:\n",
    "                print(f\"Removed {outliers_removed} outliers from {col} vs {target_col} plot\")\n",
    "        \n",
    "        # Scatter plot\n",
    "        ax.scatter(df_plot[col], df_plot[target_col], alpha=0.6, s=20)\n",
    "        \n",
    "        # Add regression line\n",
    "        sns.regplot(data=df_plot, x=col, y=target_col, ax=ax, scatter=False, color='red')\n",
    "        \n",
    "        # Calculate correlation for title\n",
    "        corr = df_plot[col].corr(df_plot[target_col])\n",
    "        \n",
    "        ax.set_xlabel(col, fontsize=10)\n",
    "        ax.set_ylabel(target_col, fontsize=10)\n",
    "        title = f'{col} vs {target_col}\\nCorrelation: {corr:.3f}'\n",
    "        if remove_outliers and outliers_removed > 0:\n",
    "            title += f'\\n({outliers_removed} outliers removed)'\n",
    "        ax.set_title(title, fontsize=11)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Hide unused subplots\n",
    "    for i in range(n_features, len(axes)):\n",
    "        axes[i].set_visible(False)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_scatter_relationships(df, target_column, feature_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997c55cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. PAIRPLOT FOR COMPREHENSIVE VIEW\n",
    "def plot_pairplot(df, target_col, feature_cols, sample_size=None):\n",
    "    \"\"\"Create pairplot showing relationships between all variables\"\"\"\n",
    "    \n",
    "    # Sample data if too large\n",
    "    if sample_size and len(df) > sample_size:\n",
    "        df_sample = df.sample(sample_size, random_state=42)\n",
    "        print(f\"Sampling {sample_size} rows for pairplot visualization\")\n",
    "    else:\n",
    "        df_sample = df\n",
    "    \n",
    "    # Select columns for pairplot\n",
    "    cols_to_plot = feature_cols + [target_col]\n",
    "    \n",
    "    # Create pairplot\n",
    "    g = sns.pairplot(df_sample[cols_to_plot], \n",
    "                     diag_kind='hist',\n",
    "                     plot_kws={'alpha': 0.6, 's': 20},\n",
    "                     diag_kws={'alpha': 0.7})\n",
    "    \n",
    "    # Highlight target variable\n",
    "    for ax in g.axes[-1, :]:  # Bottom row\n",
    "        ax.set_xlabel(ax.get_xlabel(), fontweight='bold' if ax.get_xlabel() == target_col else 'normal')\n",
    "    \n",
    "    for ax in g.axes[:, -1]:  # Right column\n",
    "        ax.set_ylabel(ax.get_ylabel(), fontweight='bold' if ax.get_ylabel() == target_col else 'normal')\n",
    "    \n",
    "    plt.suptitle(f'Pairplot: Feature Relationships with {target_col}', y=1.02, fontsize=14, fontweight='bold')\n",
    "    plt.show()\n",
    "\n",
    "plot_pairplot(df, target_column, feature_columns, sample_size=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c595b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. DISTRIBUTION PLOTS\n",
    "def plot_distributions(df, target_col, feature_cols):\n",
    "    \"\"\"Plot distributions of features and target variable\"\"\"\n",
    "    \n",
    "    n_cols = len(feature_cols) + 1  # +1 for target\n",
    "    n_rows = 2  # One for histograms, one for box plots\n",
    "    \n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(4*n_cols, 8))\n",
    "    \n",
    "    # Plot histograms\n",
    "    for i, col in enumerate(feature_cols + [target_col]):\n",
    "        ax = axes[0, i]\n",
    "        ax.hist(df[col], bins=30, alpha=0.7, edgecolor='black')\n",
    "        ax.set_title(f'Distribution of {col}', fontsize=10)\n",
    "        ax.set_xlabel(col)\n",
    "        ax.set_ylabel('Frequency')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Highlight target column\n",
    "        if col == target_col:\n",
    "            ax.set_facecolor('#ffe6e6')\n",
    "    \n",
    "    # Plot box plots\n",
    "    for i, col in enumerate(feature_cols + [target_col]):\n",
    "        ax = axes[1, i]\n",
    "        ax.boxplot(df[col])\n",
    "        ax.set_title(f'Box Plot of {col}', fontsize=10)\n",
    "        ax.set_ylabel(col)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Highlight target column\n",
    "        if col == target_col:\n",
    "            ax.set_facecolor('#ffe6e6')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_distributions(df, target_column, feature_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf0d0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. FEATURE IMPORTANCE VISUALIZATION\n",
    "def plot_feature_importance(correlation_results, top_n=None):\n",
    "    \"\"\"Plot feature importance based on correlation strength\"\"\"\n",
    "    \n",
    "    if top_n:\n",
    "        plot_data = correlation_results.head(top_n)\n",
    "    else:\n",
    "        plot_data = correlation_results\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    # Create horizontal bar plot\n",
    "    colors = ['red' if x < 0 else 'blue' for x in plot_data['Pearson_Correlation']]\n",
    "    \n",
    "    plt.barh(range(len(plot_data)), plot_data['Pearson_Correlation'], color=colors, alpha=0.7)\n",
    "    plt.yticks(range(len(plot_data)), plot_data['Feature'])\n",
    "    plt.xlabel('Correlation with Target')\n",
    "    plt.title('Feature Importance (Pearson Correlation)', fontsize=14, fontweight='bold')\n",
    "    plt.grid(True, alpha=0.3, axis='x')\n",
    "    \n",
    "    # Add correlation values on bars\n",
    "    for i, (idx, row) in enumerate(plot_data.iterrows()):\n",
    "        plt.text(row['Pearson_Correlation'] + (0.01 if row['Pearson_Correlation'] > 0 else -0.01), \n",
    "                i, f'{row[\"Pearson_Correlation\"]:.3f}', \n",
    "                va='center', ha='left' if row['Pearson_Correlation'] > 0 else 'right')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_feature_importance(correlation_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2d394f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. BINNED ANALYSIS FOR NON-LINEAR RELATIONSHIPS\n",
    "def plot_binned_analysis(df, target_col, feature_cols, n_bins=10):\n",
    "    \"\"\"Analyze relationships using binned approach\"\"\"\n",
    "    \n",
    "    n_features = len(feature_cols)\n",
    "    n_cols = 2\n",
    "    n_rows = (n_features + n_cols - 1) // n_cols\n",
    "    \n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(12, 4*n_rows))\n",
    "    \n",
    "    if n_rows == 1:\n",
    "        axes = [axes] if n_cols == 1 else axes\n",
    "    else:\n",
    "        axes = axes.flatten()\n",
    "    \n",
    "    for i, col in enumerate(feature_cols):\n",
    "        ax = axes[i]\n",
    "        \n",
    "        # Create bins\n",
    "        df['bins'] = pd.cut(df[col], bins=n_bins, precision=2)\n",
    "        \n",
    "        # Calculate mean target value for each bin\n",
    "        binned_stats = df.groupby('bins')[target_col].agg(['mean', 'std', 'count']).reset_index()\n",
    "        binned_stats['bin_center'] = binned_stats['bins'].apply(lambda x: x.mid)\n",
    "        \n",
    "        # Plot mean target values\n",
    "        ax.errorbar(binned_stats['bin_center'], binned_stats['mean'], \n",
    "                   yerr=binned_stats['std'], fmt='o-', capsize=5, capthick=2)\n",
    "        \n",
    "        ax.set_xlabel(f'{col} (binned)')\n",
    "        ax.set_ylabel(f'Mean {target_col}')\n",
    "        ax.set_title(f'Binned Analysis: {col} vs {target_col}')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        ax.tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Clean up\n",
    "    df.drop('bins', axis=1, inplace=True)\n",
    "    \n",
    "    # Hide unused subplots\n",
    "    for i in range(n_features, len(axes)):\n",
    "        axes[i].set_visible(False)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_binned_analysis(df, target_column, feature_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a338ab31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. COMPREHENSIVE ANALYSIS FUNCTION\n",
    "def comprehensive_numerical_analysis(df, target_col, exclude_cols=None, \n",
    "                                   show_distributions=True, show_pairplot=True, \n",
    "                                   show_binned=True, sample_size_pairplot=500):\n",
    "    \"\"\"\n",
    "    Run comprehensive analysis of numerical relationships with target variable\n",
    "    \n",
    "    Parameters:\n",
    "    df: pandas DataFrame\n",
    "    target_col: string, name of target column\n",
    "    exclude_cols: list, columns to exclude from analysis\n",
    "    show_distributions: bool, whether to show distribution plots\n",
    "    show_pairplot: bool, whether to show pairplot\n",
    "    show_binned: bool, whether to show binned analysis\n",
    "    sample_size_pairplot: int, sample size for pairplot\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"üîç COMPREHENSIVE NUMERICAL RELATIONSHIP ANALYSIS\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Get feature columns\n",
    "    feature_cols = analyze_numerical_relationships(df, target_col, exclude_cols)\n",
    "    \n",
    "    if len(feature_cols) == 0:\n",
    "        print(\"No numerical features found for analysis!\")\n",
    "        return\n",
    "    \n",
    "    print(f\"\\nüìä Analyzing {len(feature_cols)} features against target '{target_col}'\")\n",
    "    \n",
    "    # 1. Correlation Analysis\n",
    "    print(\"\\n1Ô∏è‚É£ CORRELATION ANALYSIS\")\n",
    "    correlation_results = correlation_analysis(df, target_col, feature_cols)\n",
    "    \n",
    "    # 2. Correlation Heatmap\n",
    "    print(\"\\n2Ô∏è‚É£ CORRELATION HEATMAP\")\n",
    "    plot_correlation_heatmap(df, target_col, feature_cols)\n",
    "    \n",
    "    # 3. Scatter Plots\n",
    "    print(\"\\n3Ô∏è‚É£ SCATTER PLOTS WITH REGRESSION LINES\")\n",
    "    plot_scatter_relationships(df, target_col, feature_cols)\n",
    "    \n",
    "    # 4. Feature Importance\n",
    "    print(\"\\n4Ô∏è‚É£ FEATURE IMPORTANCE\")\n",
    "    plot_feature_importance(correlation_results)\n",
    "    \n",
    "    # 5. Optional: Distributions\n",
    "    if show_distributions:\n",
    "        print(\"\\n5Ô∏è‚É£ DISTRIBUTION ANALYSIS\")\n",
    "        plot_distributions(df, target_col, feature_cols)\n",
    "    \n",
    "    # 6. Optional: Pairplot\n",
    "    if show_pairplot and len(feature_cols) <= 10:  # Limit for readability\n",
    "        print(\"\\n6Ô∏è‚É£ PAIRPLOT ANALYSIS\")\n",
    "        plot_pairplot(df, target_col, feature_cols, sample_size_pairplot)\n",
    "    elif show_pairplot:\n",
    "        print(f\"\\n‚ö†Ô∏è Skipping pairplot: too many features ({len(feature_cols)}). Limit is 10.\")\n",
    "    \n",
    "    # 7. Optional: Binned Analysis\n",
    "    if show_binned:\n",
    "        print(\"\\n7Ô∏è‚É£ BINNED ANALYSIS\")\n",
    "        plot_binned_analysis(df, target_col, feature_cols)\n",
    "    \n",
    "    print(\"\\n‚úÖ Analysis complete!\")\n",
    "    \n",
    "    return correlation_results\n",
    "\n",
    "# Example usage with all options\n",
    "results = comprehensive_numerical_analysis(\n",
    "    df=df, \n",
    "    target_col='target',\n",
    "    show_distributions=True,\n",
    "    show_pairplot=True,\n",
    "    show_binned=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3dcb2de",
   "metadata": {},
   "source": [
    "## üöÄ Quick Start Guide\n",
    "\n",
    "### For Your Own Dataset:\n",
    "\n",
    "```python\n",
    "# Load your data\n",
    "df = pd.read_csv('your_data.csv')  # or pd.read_excel(), etc.\n",
    "\n",
    "# Quick analysis\n",
    "results = comprehensive_numerical_analysis(\n",
    "    df=df, \n",
    "    target_col='your_target_column_name',\n",
    "    exclude_cols=['id', 'date'],  # columns to exclude\n",
    "    show_distributions=True,\n",
    "    show_pairplot=True,\n",
    "    show_binned=True\n",
    ")\n",
    "```\n",
    "\n",
    "### Individual Visualization Functions:\n",
    "\n",
    "1. **`correlation_analysis(df, target_col, feature_cols)`** - Calculate correlations\n",
    "2. **`plot_correlation_heatmap(df, target_col, feature_cols)`** - Correlation heatmap\n",
    "3. **`plot_scatter_relationships(df, target_col, feature_cols)`** - Scatter plots with regression\n",
    "4. **`plot_feature_importance(correlation_results)`** - Feature importance bars\n",
    "5. **`plot_distributions(df, target_col, feature_cols)`** - Distribution analysis\n",
    "6. **`plot_pairplot(df, target_col, feature_cols)`** - Comprehensive pairplot\n",
    "7. **`plot_binned_analysis(df, target_col, feature_cols)`** - Binned relationship analysis\n",
    "\n",
    "### Key Features:\n",
    "- ‚úÖ **Correlation Analysis**: Pearson & Spearman correlations with p-values\n",
    "- ‚úÖ **Multiple Visualizations**: Scatter plots, heatmaps, distributions, pairplots\n",
    "- ‚úÖ **Feature Importance**: Ranked by correlation strength\n",
    "- ‚úÖ **Non-linear Detection**: Binned analysis for complex relationships\n",
    "- ‚úÖ **Statistical Significance**: P-values for correlation tests\n",
    "- ‚úÖ **Flexible & Modular**: Use individual functions or comprehensive analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9fb9801",
   "metadata": {},
   "source": [
    "# üìä CATEGORICAL VARIABLES vs NUMERICAL TARGET\n",
    "\n",
    "## Functions for analyzing relationships between categorical features and numerical target variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a61d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional imports for categorical analysis\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Create sample dataset with categorical variables for demonstration\n",
    "np.random.seed(42)\n",
    "n_samples = 1000\n",
    "\n",
    "# Create categorical variables with different relationships to target\n",
    "categories_a = np.random.choice(['Category_A', 'Category_B', 'Category_C', 'Category_D'], n_samples, p=[0.3, 0.25, 0.25, 0.2])\n",
    "categories_b = np.random.choice(['Type_1', 'Type_2', 'Type_3'], n_samples, p=[0.4, 0.35, 0.25])\n",
    "categories_c = np.random.choice(['Low', 'Medium', 'High'], n_samples, p=[0.33, 0.34, 0.33])\n",
    "categories_d = np.random.choice(['Yes', 'No'], n_samples, p=[0.6, 0.4])\n",
    "\n",
    "# Create target variable with different effects from categorical variables\n",
    "target_cat = np.random.normal(0, 1, n_samples)\n",
    "\n",
    "# Add categorical effects to target\n",
    "category_effects = {\n",
    "    'Category_A': 2.0, 'Category_B': 0.5, 'Category_C': -1.0, 'Category_D': -0.5,\n",
    "    'Type_1': 1.5, 'Type_2': 0.0, 'Type_3': -1.2,\n",
    "    'Low': -1.8, 'Medium': 0.2, 'High': 1.6,\n",
    "    'Yes': 0.8, 'No': -0.8\n",
    "}\n",
    "\n",
    "for i in range(n_samples):\n",
    "    target_cat[i] += category_effects[categories_a[i]]\n",
    "    target_cat[i] += category_effects[categories_b[i]]\n",
    "    target_cat[i] += category_effects[categories_c[i]]\n",
    "    target_cat[i] += category_effects[categories_d[i]]\n",
    "\n",
    "# Create DataFrame with categorical variables\n",
    "df_cat = pd.DataFrame({\n",
    "    'feature_group': categories_a,\n",
    "    'product_type': categories_b,\n",
    "    'priority_level': categories_c,\n",
    "    'has_feature': categories_d,\n",
    "    'target_value': target_cat\n",
    "})\n",
    "\n",
    "print(\"Sample dataset with categorical variables created:\")\n",
    "print(df_cat.head(10))\n",
    "print(f\"\\nDataset shape: {df_cat.shape}\")\n",
    "print(f\"\\nData types:\\n{df_cat.dtypes}\")\n",
    "print(f\"\\nCategorical value counts:\")\n",
    "for col in df_cat.select_dtypes(include=['object']).columns:\n",
    "    print(f\"\\n{col}:\")\n",
    "    print(df_cat[col].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a9e738",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_categorical_relationships(df, target_col, exclude_cols=None):\n",
    "    \"\"\"\n",
    "    Identify categorical columns and prepare for analysis\n",
    "    \n",
    "    Parameters:\n",
    "    df: pandas DataFrame\n",
    "    target_col: string, name of target column\n",
    "    exclude_cols: list, columns to exclude from analysis\n",
    "    \"\"\"\n",
    "    \n",
    "    if exclude_cols is None:\n",
    "        exclude_cols = []\n",
    "    \n",
    "    # Select categorical columns (object, category types)\n",
    "    categorical_cols = df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "    \n",
    "    # Remove target column and excluded columns\n",
    "    feature_cols = [col for col in categorical_cols if col != target_col and col not in exclude_cols]\n",
    "    \n",
    "    print(f\"Analyzing relationships between {len(feature_cols)} categorical features and target '{target_col}'\")\n",
    "    print(f\"Categorical features: {feature_cols}\")\n",
    "    \n",
    "    # Check if target is numerical\n",
    "    if not pd.api.types.is_numeric_dtype(df[target_col]):\n",
    "        raise ValueError(f\"Target column '{target_col}' must be numerical\")\n",
    "    \n",
    "    return feature_cols\n",
    "\n",
    "# Example usage\n",
    "target_col_cat = 'target_value'\n",
    "categorical_features = analyze_categorical_relationships(df_cat, target_col_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa844717",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. STATISTICAL ANALYSIS FOR CATEGORICAL VARIABLES\n",
    "def categorical_statistical_analysis(df, target_col, categorical_cols):\n",
    "    \"\"\"\n",
    "    Perform statistical tests for categorical variables vs numerical target\n",
    "    \"\"\"\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for col in categorical_cols:\n",
    "        # Get groups\n",
    "        groups = [df[df[col] == category][target_col].values for category in df[col].unique()]\n",
    "        \n",
    "        # Remove empty groups\n",
    "        groups = [group for group in groups if len(group) > 0]\n",
    "        \n",
    "        if len(groups) < 2:\n",
    "            continue\n",
    "            \n",
    "        # Perform ANOVA (Analysis of Variance)\n",
    "        try:\n",
    "            f_stat, p_value_anova = stats.f_oneway(*groups)\n",
    "        except:\n",
    "            f_stat, p_value_anova = np.nan, np.nan\n",
    "        \n",
    "        # Perform Kruskal-Wallis test (non-parametric alternative to ANOVA)\n",
    "        try:\n",
    "            h_stat, p_value_kw = stats.kruskal(*groups)\n",
    "        except:\n",
    "            h_stat, p_value_kw = np.nan, np.nan\n",
    "        \n",
    "        # Calculate effect size (eta-squared for ANOVA)\n",
    "        try:\n",
    "            # Total sum of squares\n",
    "            grand_mean = df[target_col].mean()\n",
    "            ss_total = ((df[target_col] - grand_mean) ** 2).sum()\n",
    "            \n",
    "            # Between-group sum of squares\n",
    "            ss_between = 0\n",
    "            for category in df[col].unique():\n",
    "                group_data = df[df[col] == category][target_col]\n",
    "                if len(group_data) > 0:\n",
    "                    group_mean = group_data.mean()\n",
    "                    ss_between += len(group_data) * (group_mean - grand_mean) ** 2\n",
    "            \n",
    "            eta_squared = ss_between / ss_total if ss_total > 0 else 0\n",
    "        except:\n",
    "            eta_squared = np.nan\n",
    "        \n",
    "        # Calculate descriptive statistics\n",
    "        group_stats = df.groupby(col)[target_col].agg(['count', 'mean', 'std']).round(3)\n",
    "        \n",
    "        results.append({\n",
    "            'Feature': col,\n",
    "            'Unique_Categories': df[col].nunique(),\n",
    "            'F_Statistic': f_stat,\n",
    "            'ANOVA_p_value': p_value_anova,\n",
    "            'Kruskal_Wallis_H': h_stat,\n",
    "            'KW_p_value': p_value_kw,\n",
    "            'Effect_Size_EtaSquared': eta_squared,\n",
    "            'Group_Stats': group_stats\n",
    "        })\n",
    "    \n",
    "    results_df = pd.DataFrame(results)\n",
    "    \n",
    "    if len(results_df) > 0:\n",
    "        results_df = results_df.sort_values('Effect_Size_EtaSquared', ascending=False)\n",
    "        \n",
    "        print(\"CATEGORICAL STATISTICAL ANALYSIS:\")\n",
    "        print(\"=\" * 60)\n",
    "        print(\"ANOVA: Tests if means differ significantly between categories\")\n",
    "        print(\"Kruskal-Wallis: Non-parametric alternative to ANOVA\")\n",
    "        print(\"Effect Size (Œ∑¬≤): 0.01=small, 0.06=medium, 0.14=large effect\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        display_cols = ['Feature', 'Unique_Categories', 'F_Statistic', 'ANOVA_p_value', \n",
    "                       'Kruskal_Wallis_H', 'KW_p_value', 'Effect_Size_EtaSquared']\n",
    "        print(results_df[display_cols].round(4))\n",
    "        \n",
    "        # Show group statistics for top features\n",
    "        print(f\"\\nüìä GROUP STATISTICS FOR TOP FEATURES:\")\n",
    "        for i, row in results_df.head(3).iterrows():\n",
    "            print(f\"\\n{row['Feature']}:\")\n",
    "            print(row['Group_Stats'])\n",
    "    \n",
    "    return results_df\n",
    "\n",
    "# Run statistical analysis\n",
    "stats_results = categorical_statistical_analysis(df_cat, target_col_cat, categorical_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc8fb9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. BOX PLOTS FOR CATEGORICAL VARIABLES\n",
    "def plot_categorical_boxplots(df, target_col, categorical_cols, cols_per_row=2):\n",
    "    \"\"\"\n",
    "    Create box plots for each categorical variable vs target\n",
    "    \"\"\"\n",
    "    \n",
    "    n_features = len(categorical_cols)\n",
    "    n_rows = (n_features + cols_per_row - 1) // cols_per_row\n",
    "    \n",
    "    fig, axes = plt.subplots(n_rows, cols_per_row, figsize=(6*cols_per_row, 5*n_rows))\n",
    "    \n",
    "    # Handle single subplot case\n",
    "    if n_rows == 1 and cols_per_row == 1:\n",
    "        axes = [axes]\n",
    "    elif n_rows == 1:\n",
    "        axes = axes\n",
    "    else:\n",
    "        axes = axes.flatten()\n",
    "    \n",
    "    for i, col in enumerate(categorical_cols):\n",
    "        ax = axes[i]\n",
    "        \n",
    "        # Create box plot\n",
    "        df.boxplot(column=target_col, by=col, ax=ax)\n",
    "        \n",
    "        # Customize plot\n",
    "        ax.set_title(f'{col} vs {target_col}')\n",
    "        ax.set_xlabel(col)\n",
    "        ax.set_ylabel(target_col)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Rotate x-axis labels if needed\n",
    "        labels = ax.get_xticklabels()\n",
    "        if any(len(label.get_text()) > 8 for label in labels):\n",
    "            ax.tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Hide unused subplots\n",
    "    for i in range(n_features, len(axes)):\n",
    "        axes[i].set_visible(False)\n",
    "    \n",
    "    plt.suptitle('')  # Remove default suptitle\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_categorical_boxplots(df_cat, target_col_cat, categorical_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe32d786",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. VIOLIN PLOTS FOR DISTRIBUTION VISUALIZATION\n",
    "def plot_categorical_violins(df, target_col, categorical_cols, cols_per_row=2):\n",
    "    \"\"\"\n",
    "    Create violin plots showing distribution shape for each category\n",
    "    \"\"\"\n",
    "    \n",
    "    n_features = len(categorical_cols)\n",
    "    n_rows = (n_features + cols_per_row - 1) // cols_per_row\n",
    "    \n",
    "    fig, axes = plt.subplots(n_rows, cols_per_row, figsize=(8*cols_per_row, 5*n_rows))\n",
    "    \n",
    "    # Handle single subplot case\n",
    "    if n_rows == 1 and cols_per_row == 1:\n",
    "        axes = [axes]\n",
    "    elif n_rows == 1:\n",
    "        axes = axes\n",
    "    else:\n",
    "        axes = axes.flatten()\n",
    "    \n",
    "    for i, col in enumerate(categorical_cols):\n",
    "        ax = axes[i]\n",
    "        \n",
    "        # Create violin plot\n",
    "        sns.violinplot(data=df, x=col, y=target_col, ax=ax)\n",
    "        \n",
    "        # Customize plot\n",
    "        ax.set_title(f'Distribution of {target_col} by {col}', fontsize=12, fontweight='bold')\n",
    "        ax.set_xlabel(col)\n",
    "        ax.set_ylabel(target_col)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Rotate x-axis labels if needed\n",
    "        labels = ax.get_xticklabels()\n",
    "        if any(len(label.get_text()) > 8 for label in labels):\n",
    "            ax.tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        # Add mean markers\n",
    "        means = df.groupby(col)[target_col].mean()\n",
    "        for j, (category, mean_val) in enumerate(means.items()):\n",
    "            ax.plot(j, mean_val, marker='D', color='red', markersize=8, markeredgecolor='white', markeredgewidth=1)\n",
    "    \n",
    "    # Hide unused subplots\n",
    "    for i in range(n_features, len(axes)):\n",
    "        axes[i].set_visible(False)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_categorical_violins(df_cat, target_col_cat, categorical_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2a1628",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. BAR PLOTS WITH CONFIDENCE INTERVALS\n",
    "def plot_categorical_means(df, target_col, categorical_cols, cols_per_row=2):\n",
    "    \"\"\"\n",
    "    Create bar plots showing mean target values by category with confidence intervals\n",
    "    \"\"\"\n",
    "    \n",
    "    n_features = len(categorical_cols)\n",
    "    n_rows = (n_features + cols_per_row - 1) // cols_per_row\n",
    "    \n",
    "    fig, axes = plt.subplots(n_rows, cols_per_row, figsize=(8*cols_per_row, 5*n_rows))\n",
    "    \n",
    "    # Handle single subplot case\n",
    "    if n_rows == 1 and cols_per_row == 1:\n",
    "        axes = [axes]\n",
    "    elif n_rows == 1:\n",
    "        axes = axes\n",
    "    else:\n",
    "        axes = axes.flatten()\n",
    "    \n",
    "    for i, col in enumerate(categorical_cols):\n",
    "        ax = axes[i]\n",
    "        \n",
    "        # Calculate statistics\n",
    "        stats_data = df.groupby(col)[target_col].agg(['mean', 'std', 'count', 'sem']).reset_index()\n",
    "        stats_data['ci'] = stats_data['sem'] * 1.96  # 95% confidence interval\n",
    "        \n",
    "        # Create bar plot\n",
    "        bars = ax.bar(stats_data[col], stats_data['mean'], \n",
    "                     yerr=stats_data['ci'], capsize=5, alpha=0.7,\n",
    "                     color=plt.cm.Set3(np.linspace(0, 1, len(stats_data))))\n",
    "        \n",
    "        # Customize plot\n",
    "        ax.set_title(f'Mean {target_col} by {col}', fontsize=12, fontweight='bold')\n",
    "        ax.set_xlabel(col)\n",
    "        ax.set_ylabel(f'Mean {target_col}')\n",
    "        ax.grid(True, alpha=0.3, axis='y')\n",
    "        \n",
    "        # Add value labels on bars\n",
    "        for bar, mean_val, count in zip(bars, stats_data['mean'], stats_data['count']):\n",
    "            height = bar.get_height()\n",
    "            ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                   f'{mean_val:.2f}\\n(n={count})',\n",
    "                   ha='center', va='bottom', fontsize=9)\n",
    "        \n",
    "        # Rotate x-axis labels if needed\n",
    "        labels = ax.get_xticklabels()\n",
    "        if any(len(label.get_text()) > 8 for label in labels):\n",
    "            ax.tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Hide unused subplots\n",
    "    for i in range(n_features, len(axes)):\n",
    "        axes[i].set_visible(False)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_categorical_means(df_cat, target_col_cat, categorical_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a1780a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. SWARM/STRIP PLOTS FOR INDIVIDUAL DATA POINTS\n",
    "def plot_categorical_swarm(df, target_col, categorical_cols, cols_per_row=2, sample_size=1000):\n",
    "    \"\"\"\n",
    "    Create swarm plots showing individual data points for each category\n",
    "    \"\"\"\n",
    "    \n",
    "    # Sample data if too large\n",
    "    if len(df) > sample_size:\n",
    "        df_sample = df.sample(sample_size, random_state=42)\n",
    "        print(f\"Sampling {sample_size} rows for swarm plot visualization\")\n",
    "    else:\n",
    "        df_sample = df\n",
    "    \n",
    "    n_features = len(categorical_cols)\n",
    "    n_rows = (n_features + cols_per_row - 1) // cols_per_row\n",
    "    \n",
    "    fig, axes = plt.subplots(n_rows, cols_per_row, figsize=(8*cols_per_row, 5*n_rows))\n",
    "    \n",
    "    # Handle single subplot case\n",
    "    if n_rows == 1 and cols_per_row == 1:\n",
    "        axes = [axes]\n",
    "    elif n_rows == 1:\n",
    "        axes = axes\n",
    "    else:\n",
    "        axes = axes.flatten()\n",
    "    \n",
    "    for i, col in enumerate(categorical_cols):\n",
    "        ax = axes[i]\n",
    "        \n",
    "        # Try swarm plot first, fallback to strip plot if too many points\n",
    "        try:\n",
    "            sns.swarmplot(data=df_sample, x=col, y=target_col, ax=ax, size=4, alpha=0.7)\n",
    "        except:\n",
    "            # Fallback to strip plot for large datasets\n",
    "            sns.stripplot(data=df_sample, x=col, y=target_col, ax=ax, size=4, alpha=0.7, jitter=True)\n",
    "        \n",
    "        # Overlay box plot\n",
    "        sns.boxplot(data=df_sample, x=col, y=target_col, ax=ax, \n",
    "                   boxprops=dict(alpha=0.3), showfliers=False)\n",
    "        \n",
    "        # Customize plot\n",
    "        ax.set_title(f'{col} vs {target_col} (Individual Points)', fontsize=12, fontweight='bold')\n",
    "        ax.set_xlabel(col)\n",
    "        ax.set_ylabel(target_col)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Rotate x-axis labels if needed\n",
    "        labels = ax.get_xticklabels()\n",
    "        if any(len(label.get_text()) > 8 for label in labels):\n",
    "            ax.tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Hide unused subplots\n",
    "    for i in range(n_features, len(axes)):\n",
    "        axes[i].set_visible(False)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_categorical_swarm(df_cat, target_col_cat, categorical_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f26bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. EFFECT SIZE VISUALIZATION\n",
    "def plot_effect_sizes(stats_results):\n",
    "    \"\"\"\n",
    "    Visualize effect sizes for categorical variables\n",
    "    \"\"\"\n",
    "    \n",
    "    if len(stats_results) == 0:\n",
    "        print(\"No statistical results to plot\")\n",
    "        return\n",
    "    \n",
    "    # Create effect size plot\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    \n",
    "    # Effect size bar plot\n",
    "    colors = ['green' if x >= 0.14 else 'orange' if x >= 0.06 else 'red' \n",
    "              for x in stats_results['Effect_Size_EtaSquared']]\n",
    "    \n",
    "    bars = ax1.barh(range(len(stats_results)), stats_results['Effect_Size_EtaSquared'], color=colors, alpha=0.7)\n",
    "    ax1.set_yticks(range(len(stats_results)))\n",
    "    ax1.set_yticklabels(stats_results['Feature'])\n",
    "    ax1.set_xlabel('Effect Size (Œ∑¬≤)')\n",
    "    ax1.set_title('Effect Sizes for Categorical Variables', fontweight='bold')\n",
    "    ax1.grid(True, alpha=0.3, axis='x')\n",
    "    \n",
    "    # Add effect size interpretation lines\n",
    "    ax1.axvline(x=0.01, color='red', linestyle='--', alpha=0.7, label='Small (0.01)')\n",
    "    ax1.axvline(x=0.06, color='orange', linestyle='--', alpha=0.7, label='Medium (0.06)')\n",
    "    ax1.axvline(x=0.14, color='green', linestyle='--', alpha=0.7, label='Large (0.14)')\n",
    "    ax1.legend()\n",
    "    \n",
    "    # Add values on bars\n",
    "    for bar, value in zip(bars, stats_results['Effect_Size_EtaSquared']):\n",
    "        width = bar.get_width()\n",
    "        ax1.text(width + 0.001, bar.get_y() + bar.get_height()/2,\n",
    "                f'{value:.3f}', ha='left', va='center', fontsize=10)\n",
    "    \n",
    "    # P-value significance plot\n",
    "    p_values = stats_results['ANOVA_p_value']\n",
    "    colors_p = ['green' if x < 0.001 else 'orange' if x < 0.01 else 'red' if x < 0.05 else 'gray' \n",
    "                for x in p_values]\n",
    "    \n",
    "    bars2 = ax2.barh(range(len(stats_results)), -np.log10(p_values + 1e-16), color=colors_p, alpha=0.7)\n",
    "    ax2.set_yticks(range(len(stats_results)))\n",
    "    ax2.set_yticklabels(stats_results['Feature'])\n",
    "    ax2.set_xlabel('-log10(p-value)')\n",
    "    ax2.set_title('Statistical Significance (ANOVA)', fontweight='bold')\n",
    "    ax2.grid(True, alpha=0.3, axis='x')\n",
    "    \n",
    "    # Add significance lines\n",
    "    ax2.axvline(x=-np.log10(0.05), color='red', linestyle='--', alpha=0.7, label='p=0.05')\n",
    "    ax2.axvline(x=-np.log10(0.01), color='orange', linestyle='--', alpha=0.7, label='p=0.01')\n",
    "    ax2.axvline(x=-np.log10(0.001), color='green', linestyle='--', alpha=0.7, label='p=0.001')\n",
    "    ax2.legend()\n",
    "    \n",
    "    # Add p-values on bars\n",
    "    for bar, p_val in zip(bars2, p_values):\n",
    "        width = bar.get_width()\n",
    "        ax2.text(width + 0.1, bar.get_y() + bar.get_height()/2,\n",
    "                f'p={p_val:.3f}' if p_val >= 0.001 else 'p<0.001', \n",
    "                ha='left', va='center', fontsize=9)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_effect_sizes(stats_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cbbe67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. SUMMARY STATISTICS TABLE\n",
    "def create_summary_table(df, target_col, categorical_cols):\n",
    "    \"\"\"\n",
    "    Create comprehensive summary statistics table\n",
    "    \"\"\"\n",
    "    \n",
    "    summary_data = []\n",
    "    \n",
    "    for col in categorical_cols:\n",
    "        # Group statistics\n",
    "        group_stats = df.groupby(col)[target_col].agg([\n",
    "            'count', 'mean', 'median', 'std', 'min', 'max'\n",
    "        ]).round(3)\n",
    "        \n",
    "        # Overall statistics for comparison\n",
    "        overall_mean = df[target_col].mean()\n",
    "        overall_std = df[target_col].std()\n",
    "        \n",
    "        # Calculate standardized effect sizes (Cohen's d) relative to overall mean\n",
    "        for category in group_stats.index:\n",
    "            group_mean = group_stats.loc[category, 'mean']\n",
    "            group_std = group_stats.loc[category, 'std']\n",
    "            cohens_d = (group_mean - overall_mean) / overall_std\n",
    "            \n",
    "            summary_data.append({\n",
    "                'Feature': col,\n",
    "                'Category': category,\n",
    "                'Count': group_stats.loc[category, 'count'],\n",
    "                'Mean': group_stats.loc[category, 'mean'],\n",
    "                'Median': group_stats.loc[category, 'median'],\n",
    "                'Std': group_stats.loc[category, 'std'],\n",
    "                'Min': group_stats.loc[category, 'min'],\n",
    "                'Max': group_stats.loc[category, 'max'],\n",
    "                'Cohens_d': cohens_d,\n",
    "                'Effect_Magnitude': 'Large' if abs(cohens_d) >= 0.8 else \n",
    "                                  'Medium' if abs(cohens_d) >= 0.5 else \n",
    "                                  'Small' if abs(cohens_d) >= 0.2 else 'Negligible'\n",
    "            })\n",
    "    \n",
    "    summary_df = pd.DataFrame(summary_data)\n",
    "    \n",
    "    print(\"üìã DETAILED SUMMARY STATISTICS BY CATEGORY\")\n",
    "    print(\"=\" * 80)\n",
    "    print(\"Cohen's d interpretation: 0.2=small, 0.5=medium, 0.8=large effect\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Display by feature\n",
    "    for feature in categorical_cols:\n",
    "        feature_data = summary_df[summary_df['Feature'] == feature]\n",
    "        print(f\"\\nüîç {feature.upper()}:\")\n",
    "        display_cols = ['Category', 'Count', 'Mean', 'Median', 'Std', 'Cohens_d', 'Effect_Magnitude']\n",
    "        print(feature_data[display_cols].to_string(index=False))\n",
    "    \n",
    "    return summary_df\n",
    "\n",
    "summary_table = create_summary_table(df_cat, target_col_cat, categorical_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f147530d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. COMPREHENSIVE CATEGORICAL ANALYSIS FUNCTION\n",
    "def comprehensive_categorical_analysis(df, target_col, exclude_cols=None, \n",
    "                                     show_boxplots=True, show_violins=True, \n",
    "                                     show_means=True, show_swarm=True,\n",
    "                                     show_effect_sizes=True, show_summary=True):\n",
    "    \"\"\"\n",
    "    Run comprehensive analysis of categorical relationships with numerical target variable\n",
    "    \n",
    "    Parameters:\n",
    "    df: pandas DataFrame\n",
    "    target_col: string, name of numerical target column\n",
    "    exclude_cols: list, columns to exclude from analysis\n",
    "    show_boxplots: bool, whether to show box plots\n",
    "    show_violins: bool, whether to show violin plots\n",
    "    show_means: bool, whether to show mean comparison bar plots\n",
    "    show_swarm: bool, whether to show swarm/strip plots\n",
    "    show_effect_sizes: bool, whether to show effect size visualization\n",
    "    show_summary: bool, whether to show detailed summary statistics\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"üîç COMPREHENSIVE CATEGORICAL vs NUMERICAL TARGET ANALYSIS\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # Get categorical columns\n",
    "    categorical_cols = analyze_categorical_relationships(df, target_col, exclude_cols)\n",
    "    \n",
    "    if len(categorical_cols) == 0:\n",
    "        print(\"No categorical features found for analysis!\")\n",
    "        return None, None\n",
    "    \n",
    "    print(f\"\\nüìä Analyzing {len(categorical_cols)} categorical features against numerical target '{target_col}'\")\n",
    "    \n",
    "    # 1. Statistical Analysis\n",
    "    print(\"\\n1Ô∏è‚É£ STATISTICAL ANALYSIS\")\n",
    "    stats_results = categorical_statistical_analysis(df, target_col, categorical_cols)\n",
    "    \n",
    "    # 2. Box Plots\n",
    "    if show_boxplots:\n",
    "        print(\"\\n2Ô∏è‚É£ BOX PLOTS\")\n",
    "        plot_categorical_boxplots(df, target_col, categorical_cols)\n",
    "    \n",
    "    # 3. Violin Plots\n",
    "    if show_violins:\n",
    "        print(\"\\n3Ô∏è‚É£ VIOLIN PLOTS (Distribution Shapes)\")\n",
    "        plot_categorical_violins(df, target_col, categorical_cols)\n",
    "    \n",
    "    # 4. Mean Comparison Bar Plots\n",
    "    if show_means:\n",
    "        print(\"\\n4Ô∏è‚É£ MEAN COMPARISON WITH CONFIDENCE INTERVALS\")\n",
    "        plot_categorical_means(df, target_col, categorical_cols)\n",
    "    \n",
    "    # 5. Effect Size Visualization\n",
    "    if show_effect_sizes and len(stats_results) > 0:\n",
    "        print(\"\\n5Ô∏è‚É£ EFFECT SIZE & SIGNIFICANCE VISUALIZATION\")\n",
    "        plot_effect_sizes(stats_results)\n",
    "    \n",
    "    # 6. Swarm Plots\n",
    "    if show_swarm:\n",
    "        print(\"\\n6Ô∏è‚É£ INDIVIDUAL DATA POINTS (SWARM PLOTS)\")\n",
    "        plot_categorical_swarm(df, target_col, categorical_cols)\n",
    "    \n",
    "    # 7. Summary Statistics\n",
    "    if show_summary:\n",
    "        print(\"\\n7Ô∏è‚É£ DETAILED SUMMARY STATISTICS\")\n",
    "        summary_table = create_summary_table(df, target_col, categorical_cols)\n",
    "    else:\n",
    "        summary_table = None\n",
    "    \n",
    "    print(\"\\n‚úÖ Categorical analysis complete!\")\n",
    "    \n",
    "    return stats_results, summary_table\n",
    "\n",
    "# Example usage with all options\n",
    "cat_stats_results, cat_summary = comprehensive_categorical_analysis(\n",
    "    df=df_cat, \n",
    "    target_col='target_value',\n",
    "    show_boxplots=True,\n",
    "    show_violins=True,\n",
    "    show_means=True,\n",
    "    show_swarm=True,\n",
    "    show_effect_sizes=True,\n",
    "    show_summary=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85b1f22",
   "metadata": {},
   "source": [
    "## üöÄ Quick Start Guide for Categorical Analysis\n",
    "\n",
    "### For Your Own Dataset:\n",
    "\n",
    "```python\n",
    "# Load your data\n",
    "df = pd.read_csv('your_data.csv')\n",
    "\n",
    "# Quick categorical analysis\n",
    "cat_stats, cat_summary = comprehensive_categorical_analysis(\n",
    "    df=df, \n",
    "    target_col='your_numerical_target_column',\n",
    "    exclude_cols=['id', 'timestamp'],  # columns to exclude\n",
    "    show_boxplots=True,\n",
    "    show_violins=True,\n",
    "    show_means=True,\n",
    "    show_swarm=True,\n",
    "    show_effect_sizes=True,\n",
    "    show_summary=True\n",
    ")\n",
    "```\n",
    "\n",
    "### Individual Categorical Visualization Functions:\n",
    "\n",
    "1. **`categorical_statistical_analysis(df, target_col, categorical_cols)`** - ANOVA & Kruskal-Wallis tests\n",
    "2. **`plot_categorical_boxplots(df, target_col, categorical_cols)`** - Box plots for each category\n",
    "3. **`plot_categorical_violins(df, target_col, categorical_cols)`** - Distribution shapes by category\n",
    "4. **`plot_categorical_means(df, target_col, categorical_cols)`** - Mean comparison with confidence intervals\n",
    "5. **`plot_categorical_swarm(df, target_col, categorical_cols)`** - Individual data points visualization\n",
    "6. **`plot_effect_sizes(stats_results)`** - Effect size and significance visualization\n",
    "7. **`create_summary_table(df, target_col, categorical_cols)`** - Detailed statistics by category\n",
    "\n",
    "### Key Features for Categorical Analysis:\n",
    "- ‚úÖ **Statistical Tests**: ANOVA and Kruskal-Wallis for group differences\n",
    "- ‚úÖ **Effect Sizes**: Eta-squared and Cohen's d for practical significance\n",
    "- ‚úÖ **Multiple Visualizations**: Box plots, violin plots, bar charts, swarm plots\n",
    "- ‚úÖ **Confidence Intervals**: Statistical uncertainty visualization\n",
    "- ‚úÖ **Distribution Comparison**: Shape analysis across categories\n",
    "- ‚úÖ **Individual Points**: See actual data distribution within categories\n",
    "- ‚úÖ **Comprehensive Summary**: Detailed statistics for each category"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c13d7a",
   "metadata": {},
   "source": [
    "# ü§ñ MACHINE LEARNING MODEL FOR NUMERICAL PREDICTION\n",
    "\n",
    "## Comprehensive ML pipeline for predicting estimated_loss with feature importance analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49fa465",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional imports for machine learning\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import xgboost as xgb\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"‚úÖ Machine learning libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36f34b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create realistic dataset for estimated_loss prediction\n",
    "np.random.seed(42)\n",
    "n_samples = 5000\n",
    "\n",
    "# Create mixed feature dataset\n",
    "data_ml = {\n",
    "    # Numerical features\n",
    "    'transaction_amount': np.random.lognormal(3, 1.5, n_samples),  # Transaction amounts\n",
    "    'account_age_days': np.random.exponential(365, n_samples),     # Account age\n",
    "    'previous_claims': np.random.poisson(2, n_samples),           # Previous claims count\n",
    "    'risk_score': np.random.beta(2, 5, n_samples) * 100,         # Risk score 0-100\n",
    "    'merchant_rating': np.random.normal(4.2, 0.8, n_samples),    # Merchant rating 1-5\n",
    "    \n",
    "    # Categorical features\n",
    "    'transaction_type': np.random.choice(['purchase', 'transfer', 'withdrawal', 'refund'], \n",
    "                                       n_samples, p=[0.6, 0.2, 0.15, 0.05]),\n",
    "    'merchant_category': np.random.choice(['retail', 'food', 'travel', 'entertainment', 'other'], \n",
    "                                        n_samples, p=[0.3, 0.25, 0.2, 0.15, 0.1]),\n",
    "    'user_tier': np.random.choice(['bronze', 'silver', 'gold', 'platinum'], \n",
    "                                n_samples, p=[0.4, 0.3, 0.2, 0.1]),\n",
    "    'payment_method': np.random.choice(['credit_card', 'debit_card', 'bank_transfer', 'digital_wallet'], \n",
    "                                     n_samples, p=[0.4, 0.3, 0.2, 0.1]),\n",
    "    'country': np.random.choice(['US', 'UK', 'CA', 'AU', 'DE'], \n",
    "                              n_samples, p=[0.5, 0.2, 0.15, 0.1, 0.05])\n",
    "}\n",
    "\n",
    "# Create target variable (estimated_loss) with realistic relationships\n",
    "estimated_loss = np.zeros(n_samples)\n",
    "\n",
    "for i in range(n_samples):\n",
    "    base_loss = 0\n",
    "    \n",
    "    # Transaction amount effect (higher amounts = higher potential loss)\n",
    "    base_loss += data_ml['transaction_amount'][i] * 0.02\n",
    "    \n",
    "    # Risk score effect\n",
    "    base_loss += data_ml['risk_score'][i] * 0.5\n",
    "    \n",
    "    # Previous claims effect\n",
    "    base_loss += data_ml['previous_claims'][i] * 8\n",
    "    \n",
    "    # Account age effect (newer accounts riskier)\n",
    "    base_loss += max(0, (100 - data_ml['account_age_days'][i]/10)) * 0.3\n",
    "    \n",
    "    # Merchant rating effect (lower rating = higher risk)\n",
    "    base_loss += (5 - data_ml['merchant_rating'][i]) * 10\n",
    "    \n",
    "    # Categorical effects\n",
    "    transaction_effects = {'purchase': 0, 'transfer': 15, 'withdrawal': 25, 'refund': -10}\n",
    "    base_loss += transaction_effects[data_ml['transaction_type'][i]]\n",
    "    \n",
    "    category_effects = {'retail': 0, 'food': 5, 'travel': 20, 'entertainment': 10, 'other': 15}\n",
    "    base_loss += category_effects[data_ml['merchant_category'][i]]\n",
    "    \n",
    "    tier_effects = {'bronze': 20, 'silver': 10, 'gold': 5, 'platinum': 0}\n",
    "    base_loss += tier_effects[data_ml['user_tier'][i]]\n",
    "    \n",
    "    payment_effects = {'credit_card': 0, 'debit_card': 5, 'bank_transfer': 10, 'digital_wallet': 8}\n",
    "    base_loss += payment_effects[data_ml['payment_method'][i]]\n",
    "    \n",
    "    country_effects = {'US': 0, 'UK': 5, 'CA': 3, 'AU': 7, 'DE': 4}\n",
    "    base_loss += country_effects[data_ml['country'][i]]\n",
    "    \n",
    "    # Add some noise\n",
    "    base_loss += np.random.normal(0, 15)\n",
    "    \n",
    "    # Ensure non-negative\n",
    "    estimated_loss[i] = max(0, base_loss)\n",
    "\n",
    "data_ml['estimated_loss'] = estimated_loss\n",
    "\n",
    "# Create DataFrame\n",
    "df_ml = pd.DataFrame(data_ml)\n",
    "\n",
    "print(\"Machine Learning Dataset Created:\")\n",
    "print(f\"Shape: {df_ml.shape}\")\n",
    "print(f\"\\nFirst 5 rows:\")\n",
    "print(df_ml.head())\n",
    "print(f\"\\nTarget variable statistics:\")\n",
    "print(df_ml['estimated_loss'].describe())\n",
    "print(f\"\\nData types:\")\n",
    "print(df_ml.dtypes)\n",
    "print(f\"\\nMissing values:\")\n",
    "print(df_ml.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120087b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preprocessing function\n",
    "def prepare_ml_data(df, target_col, test_size=0.2, random_state=42):\n",
    "    \"\"\"\n",
    "    Prepare data for machine learning with proper encoding\n",
    "    \n",
    "    Parameters:\n",
    "    df: pandas DataFrame\n",
    "    target_col: string, name of target column\n",
    "    test_size: float, proportion of data for testing\n",
    "    random_state: int, for reproducibility\n",
    "    \"\"\"\n",
    "    \n",
    "    # Separate features and target\n",
    "    X = df.drop(columns=[target_col])\n",
    "    y = df[target_col]\n",
    "    \n",
    "    # Identify numerical and categorical columns\n",
    "    numerical_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    categorical_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "    \n",
    "    print(f\"Numerical features ({len(numerical_cols)}): {numerical_cols}\")\n",
    "    print(f\"Categorical features ({len(categorical_cols)}): {categorical_cols}\")\n",
    "    \n",
    "    # Create preprocessing pipelines\n",
    "    numerical_transformer = StandardScaler()\n",
    "    categorical_transformer = OneHotEncoder(drop='first', sparse_output=False)\n",
    "    \n",
    "    # Combine preprocessing steps\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numerical_transformer, numerical_cols),\n",
    "            ('cat', categorical_transformer, categorical_cols)\n",
    "        ])\n",
    "    \n",
    "    # Split the data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=random_state\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nData split:\")\n",
    "    print(f\"Training set: {X_train.shape[0]} samples\")\n",
    "    print(f\"Test set: {X_test.shape[0]} samples\")\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test, preprocessor, numerical_cols, categorical_cols\n",
    "\n",
    "# Prepare the data\n",
    "X_train, X_test, y_train, y_test, preprocessor, num_cols, cat_cols = prepare_ml_data(\n",
    "    df_ml, 'estimated_loss'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21d2bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model training and evaluation class\n",
    "class EstimatedLossPredictor:\n",
    "    \"\"\"\n",
    "    Comprehensive machine learning model for predicting estimated_loss\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, preprocessor):\n",
    "        self.preprocessor = preprocessor\n",
    "        self.models = {}\n",
    "        self.results = {}\n",
    "        self.best_model = None\n",
    "        self.best_score = float('-inf')\n",
    "        \n",
    "    def define_models(self):\n",
    "        \"\"\"Define different models to compare\"\"\"\n",
    "        self.models = {\n",
    "            'Linear Regression': LinearRegression(),\n",
    "            'Ridge Regression': Ridge(alpha=1.0),\n",
    "            'Lasso Regression': Lasso(alpha=1.0),\n",
    "            'Decision Tree': DecisionTreeRegressor(random_state=42, max_depth=10),\n",
    "            'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42, max_depth=10),\n",
    "            'Gradient Boosting': GradientBoostingRegressor(n_estimators=100, random_state=42, max_depth=6),\n",
    "            'XGBoost': xgb.XGBRegressor(n_estimators=100, random_state=42, max_depth=6)\n",
    "        }\n",
    "        \n",
    "    def train_models(self, X_train, y_train, cv_folds=5):\n",
    "        \"\"\"Train all models and perform cross-validation\"\"\"\n",
    "        \n",
    "        print(\"üîÑ Training models...\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        for name, model in self.models.items():\n",
    "            print(f\"\\nTraining {name}...\")\n",
    "            \n",
    "            # Create pipeline\n",
    "            pipeline = Pipeline([\n",
    "                ('preprocessor', self.preprocessor),\n",
    "                ('regressor', model)\n",
    "            ])\n",
    "            \n",
    "            # Cross-validation\n",
    "            cv_scores = cross_val_score(pipeline, X_train, y_train, \n",
    "                                      cv=cv_folds, scoring='r2')\n",
    "            \n",
    "            # Fit the model\n",
    "            pipeline.fit(X_train, y_train)\n",
    "            \n",
    "            # Store results\n",
    "            self.results[name] = {\n",
    "                'pipeline': pipeline,\n",
    "                'cv_mean': cv_scores.mean(),\n",
    "                'cv_std': cv_scores.std(),\n",
    "                'cv_scores': cv_scores\n",
    "            }\n",
    "            \n",
    "            print(f\"CV R¬≤ Score: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\")\n",
    "            \n",
    "            # Track best model\n",
    "            if cv_scores.mean() > self.best_score:\n",
    "                self.best_score = cv_scores.mean()\n",
    "                self.best_model = name\n",
    "        \n",
    "        print(f\"\\nüèÜ Best model: {self.best_model} (R¬≤ = {self.best_score:.4f})\")\n",
    "    \n",
    "    def evaluate_models(self, X_test, y_test):\n",
    "        \"\"\"Evaluate all models on test set\"\"\"\n",
    "        \n",
    "        print(\"\\nüìä Model Evaluation on Test Set:\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        evaluation_results = []\n",
    "        \n",
    "        for name, result in self.results.items():\n",
    "            pipeline = result['pipeline']\n",
    "            \n",
    "            # Predictions\n",
    "            y_pred = pipeline.predict(X_test)\n",
    "            \n",
    "            # Metrics\n",
    "            r2 = r2_score(y_test, y_pred)\n",
    "            mse = mean_squared_error(y_test, y_pred)\n",
    "            rmse = np.sqrt(mse)\n",
    "            mae = mean_absolute_error(y_test, y_pred)\n",
    "            \n",
    "            evaluation_results.append({\n",
    "                'Model': name,\n",
    "                'R¬≤': r2,\n",
    "                'RMSE': rmse,\n",
    "                'MAE': mae,\n",
    "                'CV_R¬≤_Mean': result['cv_mean'],\n",
    "                'CV_R¬≤_Std': result['cv_std']\n",
    "            })\n",
    "        \n",
    "        # Create results DataFrame\n",
    "        eval_df = pd.DataFrame(evaluation_results)\n",
    "        eval_df = eval_df.sort_values('R¬≤', ascending=False)\n",
    "        \n",
    "        print(eval_df.round(4))\n",
    "        \n",
    "        return eval_df\n",
    "    \n",
    "    def get_feature_importance(self, feature_names=None):\n",
    "        \"\"\"Extract feature importance from the best model\"\"\"\n",
    "        \n",
    "        if self.best_model is None:\n",
    "            print(\"No models trained yet!\")\n",
    "            return None\n",
    "            \n",
    "        best_pipeline = self.results[self.best_model]['pipeline']\n",
    "        regressor = best_pipeline.named_steps['regressor']\n",
    "        \n",
    "        # Get feature names after preprocessing\n",
    "        if feature_names is None:\n",
    "            try:\n",
    "                # Get feature names from preprocessor\n",
    "                feature_names = best_pipeline.named_steps['preprocessor'].get_feature_names_out()\n",
    "            except:\n",
    "                feature_names = [f'feature_{i}' for i in range(len(regressor.feature_importances_))]\n",
    "        \n",
    "        # Extract importance based on model type\n",
    "        if hasattr(regressor, 'feature_importances_'):\n",
    "            # Tree-based models\n",
    "            importances = regressor.feature_importances_\n",
    "        elif hasattr(regressor, 'coef_'):\n",
    "            # Linear models\n",
    "            importances = np.abs(regressor.coef_)\n",
    "        else:\n",
    "            print(f\"Feature importance not available for {self.best_model}\")\n",
    "            return None\n",
    "        \n",
    "        # Create importance DataFrame\n",
    "        importance_df = pd.DataFrame({\n",
    "            'feature': feature_names,\n",
    "            'importance': importances\n",
    "        }).sort_values('importance', ascending=False)\n",
    "        \n",
    "        return importance_df\n",
    "\n",
    "# Initialize predictor\n",
    "predictor = EstimatedLossPredictor(preprocessor)\n",
    "predictor.define_models()\n",
    "\n",
    "print(\"‚úÖ EstimatedLossPredictor initialized!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8fd063",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train all models\n",
    "predictor.train_models(X_train, y_train, cv_folds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05913c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate models on test set\n",
    "evaluation_results = predictor.evaluate_models(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d298289",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance analysis and visualization\n",
    "def plot_feature_importance(importance_df, top_n=20, figsize=(12, 8)):\n",
    "    \"\"\"\n",
    "    Plot feature importance\n",
    "    \"\"\"\n",
    "    \n",
    "    # Select top N features\n",
    "    plot_data = importance_df.head(top_n)\n",
    "    \n",
    "    plt.figure(figsize=figsize)\n",
    "    \n",
    "    # Create horizontal bar plot\n",
    "    bars = plt.barh(range(len(plot_data)), plot_data['importance'], \n",
    "                   color=plt.cm.viridis(np.linspace(0, 1, len(plot_data))))\n",
    "    \n",
    "    # Customize plot\n",
    "    plt.yticks(range(len(plot_data)), plot_data['feature'])\n",
    "    plt.xlabel('Feature Importance')\n",
    "    plt.title(f'Top {top_n} Feature Importances - {predictor.best_model}', \n",
    "              fontsize=14, fontweight='bold')\n",
    "    plt.grid(True, alpha=0.3, axis='x')\n",
    "    \n",
    "    # Add importance values on bars\n",
    "    for i, (bar, importance) in enumerate(zip(bars, plot_data['importance'])):\n",
    "        width = bar.get_width()\n",
    "        plt.text(width + max(plot_data['importance']) * 0.01, \n",
    "                bar.get_y() + bar.get_height()/2,\n",
    "                f'{importance:.4f}', ha='left', va='center', fontsize=9)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Get and plot feature importance\n",
    "importance_df = predictor.get_feature_importance()\n",
    "\n",
    "if importance_df is not None:\n",
    "    print(\"\\nüîç FEATURE IMPORTANCE ANALYSIS:\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"Top 15 most important features for {predictor.best_model}:\")\n",
    "    print(importance_df.head(15).round(4))\n",
    "    \n",
    "    plot_feature_importance(importance_df, top_n=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25221c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model performance visualization\n",
    "def plot_model_comparison(evaluation_results):\n",
    "    \"\"\"\n",
    "    Create comprehensive model comparison plots\n",
    "    \"\"\"\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    \n",
    "    # 1. R¬≤ Score comparison\n",
    "    ax1 = axes[0, 0]\n",
    "    bars1 = ax1.bar(evaluation_results['Model'], evaluation_results['R¬≤'], \n",
    "                   color=plt.cm.Set3(np.linspace(0, 1, len(evaluation_results))))\n",
    "    ax1.set_title('R¬≤ Score Comparison', fontweight='bold')\n",
    "    ax1.set_ylabel('R¬≤ Score')\n",
    "    ax1.tick_params(axis='x', rotation=45)\n",
    "    ax1.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # Add values on bars\n",
    "    for bar, value in zip(bars1, evaluation_results['R¬≤']):\n",
    "        height = bar.get_height()\n",
    "        ax1.text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
    "                f'{value:.3f}', ha='center', va='bottom', fontsize=9)\n",
    "    \n",
    "    # 2. RMSE comparison\n",
    "    ax2 = axes[0, 1]\n",
    "    bars2 = ax2.bar(evaluation_results['Model'], evaluation_results['RMSE'], \n",
    "                   color=plt.cm.Set2(np.linspace(0, 1, len(evaluation_results))))\n",
    "    ax2.set_title('RMSE Comparison (Lower is Better)', fontweight='bold')\n",
    "    ax2.set_ylabel('RMSE')\n",
    "    ax2.tick_params(axis='x', rotation=45)\n",
    "    ax2.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # Add values on bars\n",
    "    for bar, value in zip(bars2, evaluation_results['RMSE']):\n",
    "        height = bar.get_height()\n",
    "        ax2.text(bar.get_x() + bar.get_width()/2., height + max(evaluation_results['RMSE']) * 0.01,\n",
    "                f'{value:.1f}', ha='center', va='bottom', fontsize=9)\n",
    "    \n",
    "    # 3. Cross-validation vs Test performance\n",
    "    ax3 = axes[1, 0]\n",
    "    x_pos = np.arange(len(evaluation_results['Model']))\n",
    "    width = 0.35\n",
    "    \n",
    "    bars3a = ax3.bar(x_pos - width/2, evaluation_results['CV_R¬≤_Mean'], width, \n",
    "                    label='CV R¬≤ Mean', alpha=0.7, color='skyblue')\n",
    "    bars3b = ax3.bar(x_pos + width/2, evaluation_results['R¬≤'], width, \n",
    "                    label='Test R¬≤', alpha=0.7, color='lightcoral')\n",
    "    \n",
    "    ax3.set_title('Cross-Validation vs Test Performance', fontweight='bold')\n",
    "    ax3.set_ylabel('R¬≤ Score')\n",
    "    ax3.set_xticks(x_pos)\n",
    "    ax3.set_xticklabels(evaluation_results['Model'], rotation=45)\n",
    "    ax3.legend()\n",
    "    ax3.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # 4. MAE comparison\n",
    "    ax4 = axes[1, 1]\n",
    "    bars4 = ax4.bar(evaluation_results['Model'], evaluation_results['MAE'], \n",
    "                   color=plt.cm.Pastel1(np.linspace(0, 1, len(evaluation_results))))\n",
    "    ax4.set_title('MAE Comparison (Lower is Better)', fontweight='bold')\n",
    "    ax4.set_ylabel('Mean Absolute Error')\n",
    "    ax4.tick_params(axis='x', rotation=45)\n",
    "    ax4.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # Add values on bars\n",
    "    for bar, value in zip(bars4, evaluation_results['MAE']):\n",
    "        height = bar.get_height()\n",
    "        ax4.text(bar.get_x() + bar.get_width()/2., height + max(evaluation_results['MAE']) * 0.01,\n",
    "                f'{value:.1f}', ha='center', va='bottom', fontsize=9)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plot model comparison\n",
    "plot_model_comparison(evaluation_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e9c95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction analysis and residuals\n",
    "def analyze_predictions(predictor, X_test, y_test, sample_size=1000):\n",
    "    \"\"\"\n",
    "    Analyze predictions from the best model\n",
    "    \"\"\"\n",
    "    \n",
    "    best_pipeline = predictor.results[predictor.best_model]['pipeline']\n",
    "    y_pred = best_pipeline.predict(X_test)\n",
    "    \n",
    "    # Sample for visualization if dataset is large\n",
    "    if len(y_test) > sample_size:\n",
    "        indices = np.random.choice(len(y_test), sample_size, replace=False)\n",
    "        y_test_sample = y_test.iloc[indices]\n",
    "        y_pred_sample = y_pred[indices]\n",
    "    else:\n",
    "        y_test_sample = y_test\n",
    "        y_pred_sample = y_pred\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    \n",
    "    # 1. Actual vs Predicted\n",
    "    ax1 = axes[0, 0]\n",
    "    ax1.scatter(y_test_sample, y_pred_sample, alpha=0.6, s=20)\n",
    "    \n",
    "    # Perfect prediction line\n",
    "    min_val = min(y_test_sample.min(), y_pred_sample.min())\n",
    "    max_val = max(y_test_sample.max(), y_pred_sample.max())\n",
    "    ax1.plot([min_val, max_val], [min_val, max_val], 'r--', lw=2, label='Perfect Prediction')\n",
    "    \n",
    "    ax1.set_xlabel('Actual Values')\n",
    "    ax1.set_ylabel('Predicted Values')\n",
    "    ax1.set_title(f'Actual vs Predicted - {predictor.best_model}', fontweight='bold')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add R¬≤ score\n",
    "    r2 = r2_score(y_test_sample, y_pred_sample)\n",
    "    ax1.text(0.05, 0.95, f'R¬≤ = {r2:.3f}', transform=ax1.transAxes, \n",
    "            bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "    \n",
    "    # 2. Residuals plot\n",
    "    ax2 = axes[0, 1]\n",
    "    residuals = y_test_sample - y_pred_sample\n",
    "    ax2.scatter(y_pred_sample, residuals, alpha=0.6, s=20)\n",
    "    ax2.axhline(y=0, color='r', linestyle='--', lw=2)\n",
    "    ax2.set_xlabel('Predicted Values')\n",
    "    ax2.set_ylabel('Residuals')\n",
    "    ax2.set_title('Residuals Plot', fontweight='bold')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 3. Residuals histogram\n",
    "    ax3 = axes[1, 0]\n",
    "    ax3.hist(residuals, bins=30, alpha=0.7, edgecolor='black')\n",
    "    ax3.set_xlabel('Residuals')\n",
    "    ax3.set_ylabel('Frequency')\n",
    "    ax3.set_title('Distribution of Residuals', fontweight='bold')\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add normal distribution overlay\n",
    "    mu, sigma = residuals.mean(), residuals.std()\n",
    "    x = np.linspace(residuals.min(), residuals.max(), 100)\n",
    "    y = ((1 / (np.sqrt(2 * np.pi) * sigma)) * \n",
    "         np.exp(-0.5 * (1 / sigma * (x - mu)) ** 2))\n",
    "    ax3_twin = ax3.twinx()\n",
    "    ax3_twin.plot(x, y * len(residuals) * (x[1] - x[0]), 'r-', lw=2, label='Normal Distribution')\n",
    "    ax3_twin.set_ylabel('Density (scaled)')\n",
    "    ax3_twin.legend()\\n    \\n    # 4. Q-Q plot for residuals normality\\n    ax4 = axes[1, 1]\\n    from scipy import stats\\n    stats.probplot(residuals, dist=\\\"norm\\\", plot=ax4)\\n    ax4.set_title('Q-Q Plot (Residuals Normality)', fontweight='bold')\\n    ax4.grid(True, alpha=0.3)\\n    \\n    plt.tight_layout()\\n    plt.show()\\n    \\n    # Print summary statistics\\n    print(f\\\"\\\\nüìà PREDICTION ANALYSIS SUMMARY:\\\")\\n    print(f\\\"Model: {predictor.best_model}\\\")\\n    print(f\\\"R¬≤ Score: {r2_score(y_test, y_pred):.4f}\\\")\\n    print(f\\\"RMSE: {np.sqrt(mean_squared_error(y_test, y_pred)):.2f}\\\")\\n    print(f\\\"MAE: {mean_absolute_error(y_test, y_pred):.2f}\\\")\\n    print(f\\\"Mean Residual: {residuals.mean():.4f}\\\")\\n    print(f\\\"Std Residual: {residuals.std():.2f}\\\")\\n    \\n    return y_pred, residuals\\n\\n# Analyze predictions\\ny_pred, residuals = analyze_predictions(predictor, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0165a21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter tuning for the best model\n",
    "def hyperparameter_tuning(predictor, X_train, y_train, model_name=None):\n",
    "    \"\"\"\n",
    "    Perform hyperparameter tuning for the best model\n",
    "    \"\"\"\n",
    "    \n",
    "    if model_name is None:\n",
    "        model_name = predictor.best_model\n",
    "    \n",
    "    print(f\\\"üîß Hyperparameter tuning for {model_name}...\\\")\\n    \\n    # Define parameter grids for different models\\n    param_grids = {\\n        'Random Forest': {\\n            'regressor__n_estimators': [50, 100, 200],\\n            'regressor__max_depth': [5, 10, 15, None],\\n            'regressor__min_samples_split': [2, 5, 10]\\n        },\\n        'Gradient Boosting': {\\n            'regressor__n_estimators': [50, 100, 200],\\n            'regressor__max_depth': [3, 5, 7],\\n            'regressor__learning_rate': [0.01, 0.1, 0.2]\\n        },\\n        'XGBoost': {\\n            'regressor__n_estimators': [50, 100, 200],\\n            'regressor__max_depth': [3, 5, 7],\\n            'regressor__learning_rate': [0.01, 0.1, 0.2]\\n        }\\n    }\\n    \\n    if model_name not in param_grids:\\n        print(f\\\"No hyperparameter grid defined for {model_name}\\\")\\n        return None\\n    \\n    # Get the base pipeline\\n    base_pipeline = predictor.results[model_name]['pipeline']\\n    \\n    # Perform grid search\\n    grid_search = GridSearchCV(\\n        base_pipeline, \\n        param_grids[model_name], \\n        cv=3,  # Reduced for speed\\n        scoring='r2',\\n        n_jobs=-1,\\n        verbose=1\\n    )\\n    \\n    grid_search.fit(X_train, y_train)\\n    \\n    print(f\\\"\\\\n‚úÖ Best parameters for {model_name}:\\\")\\n    for param, value in grid_search.best_params_.items():\\n        print(f\\\"  {param}: {value}\\\")\\n    \\n    print(f\\\"\\\\nBest CV score: {grid_search.best_score_:.4f}\\\")\\n    print(f\\\"Improvement over default: {grid_search.best_score_ - predictor.results[model_name]['cv_mean']:.4f}\\\")\\n    \\n    return grid_search.best_estimator_\\n\\n# Perform hyperparameter tuning for the best model (if it's a tree-based model)\\nif predictor.best_model in ['Random Forest', 'Gradient Boosting', 'XGBoost']:\\n    tuned_model = hyperparameter_tuning(predictor, X_train, y_train)\\nelse:\\n    print(f\\\"Hyperparameter tuning not implemented for {predictor.best_model}\\\")\\n    tuned_model = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5a5125",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model deployment functions\\ndef save_model(model, filepath='best_estimated_loss_model.pkl'):\\n    \\\"\\\"\\\"\\n    Save the trained model\\n    \\\"\\\"\\\"\\n    import joblib\\n    joblib.dump(model, filepath)\\n    print(f\\\"‚úÖ Model saved to {filepath}\\\")\\n\\ndef load_model(filepath='best_estimated_loss_model.pkl'):\\n    \\\"\\\"\\\"\\n    Load a saved model\\n    \\\"\\\"\\\"\\n    import joblib\\n    return joblib.load(filepath)\\n\\ndef predict_new_data(model, new_data):\\n    \\\"\\\"\\\"\\n    Make predictions on new data\\n    \\n    Parameters:\\n    model: trained sklearn pipeline\\n    new_data: pandas DataFrame with same features as training data\\n    \\n    Returns:\\n    predictions: numpy array of predictions\\n    \\\"\\\"\\\"\\n    return model.predict(new_data)\\n\\n# Example of saving the best model\\nbest_model_pipeline = predictor.results[predictor.best_model]['pipeline']\\nsave_model(best_model_pipeline, 'estimated_loss_predictor.pkl')\\n\\n# Example of making predictions on new data\\nprint(\\\"\\\\nüîÆ EXAMPLE: Making predictions on new data\\\")\\nprint(\\\"=\\\" * 50)\\n\\n# Create sample new data\\nnew_sample = pd.DataFrame({\\n    'transaction_amount': [150.0, 2500.0, 75.0],\\n    'account_age_days': [30, 365, 1200],\\n    'previous_claims': [0, 3, 1],\\n    'risk_score': [25.5, 75.2, 15.8],\\n    'merchant_rating': [4.5, 2.1, 4.8],\\n    'transaction_type': ['purchase', 'transfer', 'purchase'],\\n    'merchant_category': ['retail', 'travel', 'food'],\\n    'user_tier': ['bronze', 'gold', 'silver'],\\n    'payment_method': ['credit_card', 'bank_transfer', 'debit_card'],\\n    'country': ['US', 'UK', 'CA']\\n})\\n\\nprint(\\\"New data sample:\\\")\\nprint(new_sample)\\n\\n# Make predictions\\npredictions = predict_new_data(best_model_pipeline, new_sample)\\n\\nprint(f\\\"\\\\nPredicted estimated_loss values:\\\")\\nfor i, pred in enumerate(predictions):\\n    print(f\\\"Sample {i+1}: ${pred:.2f}\\\")\"antml:parameter>\n",
    "</invoke>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3fa5ee1",
   "metadata": {},
   "source": [
    "## üöÄ Quick Start Guide for ML Model\n",
    "\n",
    "### For Your Own Dataset:\n",
    "\n",
    "```python\n",
    "# 1. Load your data\n",
    "df = pd.read_csv('your_data.csv')\n",
    "\n",
    "# 2. Prepare data\n",
    "X_train, X_test, y_train, y_test, preprocessor, num_cols, cat_cols = prepare_ml_data(\n",
    "    df, target_col='estimated_loss'  # or your target column name\n",
    ")\n",
    "\n",
    "# 3. Initialize and train models\n",
    "predictor = EstimatedLossPredictor(preprocessor)\n",
    "predictor.define_models()\n",
    "predictor.train_models(X_train, y_train)\n",
    "\n",
    "# 4. Evaluate models\n",
    "evaluation_results = predictor.evaluate_models(X_test, y_test)\n",
    "\n",
    "# 5. Get feature importance\n",
    "importance_df = predictor.get_feature_importance()\n",
    "\n",
    "# 6. Save best model\n",
    "best_model = predictor.results[predictor.best_model]['pipeline']\n",
    "save_model(best_model, 'my_model.pkl')\n",
    "\n",
    "# 7. Make predictions on new data\n",
    "predictions = predict_new_data(best_model, new_data_df)\n",
    "```\n",
    "\n",
    "### Key Features of the ML Pipeline:\n",
    "\n",
    "- ‚úÖ **Multiple Models**: Linear, Ridge, Lasso, Decision Tree, Random Forest, Gradient Boosting, XGBoost\n",
    "- ‚úÖ **Automatic Preprocessing**: StandardScaler for numerical, OneHotEncoder for categorical\n",
    "- ‚úÖ **Cross-Validation**: 5-fold CV for robust model selection\n",
    "- ‚úÖ **Feature Importance**: Extract and visualize most important features\n",
    "- ‚úÖ **Model Comparison**: Comprehensive evaluation with multiple metrics\n",
    "- ‚úÖ **Hyperparameter Tuning**: Grid search for tree-based models\n",
    "- ‚úÖ **Prediction Analysis**: Residuals, Q-Q plots, actual vs predicted\n",
    "- ‚úÖ **Model Persistence**: Save and load trained models\n",
    "- ‚úÖ **Production Ready**: Functions for making predictions on new data\n",
    "\n",
    "### Evaluation Metrics:\n",
    "- **R¬≤ Score**: Proportion of variance explained (higher = better)\n",
    "- **RMSE**: Root Mean Square Error (lower = better)\n",
    "- **MAE**: Mean Absolute Error (lower = better)\n",
    "- **Cross-Validation**: Robust performance estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2551b2df",
   "metadata": {},
   "source": [
    "# üå≤ SIMPLIFIED RANDOM FOREST MODEL\n",
    "\n",
    "## Focused implementation using only RandomForestRegressor for estimated_loss prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65dd41e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simplified imports for Random Forest only\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, make_scorer, mean_absolute_percentage_error\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Create MAPE scorer for sklearn using built-in function\n",
    "mape_scorer = make_scorer(mean_absolute_percentage_error, greater_is_better=False)\n",
    "\n",
    "print(\"‚úÖ Random Forest ML libraries imported successfully!\")\n",
    "print(\"‚úÖ Using sklearn's built-in mean_absolute_percentage_error function!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c83b6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simplified Random Forest Predictor Class\n",
    "class RandomForestLossPredictor:\n",
    "    \"\"\"\n",
    "    Simplified predictor using only Random Forest for estimated_loss prediction\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, n_estimators=100, max_depth=10, random_state=42):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_depth = max_depth\n",
    "        self.random_state = random_state\n",
    "        self.model = None\n",
    "        self.pipeline = None\n",
    "        self.feature_names = None\n",
    "        self.feature_importance_df = None\n",
    "        \n",
    "    def prepare_data(self, df, target_col, test_size=0.2):\n",
    "        \"\"\"\n",
    "        Prepare data for Random Forest training\n",
    "        \"\"\"\n",
    "        print(\"üîÑ Preparing data...\")\n",
    "        \n",
    "        # Separate features and target\n",
    "        X = df.drop(columns=[target_col])\n",
    "        y = df[target_col]\n",
    "        \n",
    "        # Identify column types\n",
    "        numerical_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "        categorical_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "        \n",
    "        print(f\"Numerical features ({len(numerical_cols)}): {numerical_cols}\")\n",
    "        print(f\"Categorical features ({len(categorical_cols)}): {categorical_cols}\")\n",
    "        \n",
    "        # Create preprocessing pipeline\n",
    "        preprocessor = ColumnTransformer(\n",
    "            transformers=[\n",
    "                ('num', StandardScaler(), numerical_cols),\n",
    "                ('cat', OneHotEncoder(drop='first', sparse_output=False), categorical_cols)\n",
    "            ])\n",
    "        \n",
    "        # Split data\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=test_size, random_state=self.random_state\n",
    "        )\n",
    "        \n",
    "        print(f\"Training set: {X_train.shape[0]} samples\")\n",
    "        print(f\"Test set: {X_test.shape[0]} samples\")\n",
    "        \n",
    "        # Store for later use\n",
    "        self.X_train = X_train\n",
    "        self.X_test = X_test\n",
    "        self.y_train = y_train\n",
    "        self.y_test = y_test\n",
    "        self.preprocessor = preprocessor\n",
    "        self.numerical_cols = numerical_cols\n",
    "        self.categorical_cols = categorical_cols\n",
    "        \n",
    "        return X_train, X_test, y_train, y_test\n",
    "    \n",
    "    def train_model(self, cv_folds=5):\n",
    "        \"\"\"\n",
    "        Train Random Forest model with cross-validation using MAPE\n",
    "        \"\"\"\n",
    "        print(\"üå≤ Training Random Forest model...\")\n",
    "        \n",
    "        # Create Random Forest model\n",
    "        rf_model = RandomForestRegressor(\n",
    "            n_estimators=self.n_estimators,\n",
    "            max_depth=self.max_depth,\n",
    "            random_state=self.random_state,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        \n",
    "        # Create pipeline\n",
    "        self.pipeline = Pipeline([\n",
    "            ('preprocessor', self.preprocessor),\n",
    "            ('regressor', rf_model)\n",
    "        ])\n",
    "        \n",
    "        # Cross-validation with MAPE (note: sklearn returns negative MAPE as decimal)\n",
    "        cv_scores = cross_val_score(self.pipeline, self.X_train, self.y_train, \n",
    "                                  cv=cv_folds, scoring=mape_scorer)\n",
    "        \n",
    "        # Convert back to positive MAPE values as percentages\n",
    "        cv_mape_scores = -cv_scores * 100\n",
    "        \n",
    "        print(f\"Cross-validation MAPE scores: {cv_mape_scores}\")\n",
    "        print(f\"Mean CV MAPE: {cv_mape_scores.mean():.4f}% (+/- {cv_mape_scores.std() * 2:.4f}%)\")\n",
    "        \n",
    "        # Fit the model\n",
    "        self.pipeline.fit(self.X_train, self.y_train)\n",
    "        self.model = self.pipeline.named_steps['regressor']\n",
    "        \n",
    "        # Get feature names after preprocessing\n",
    "        try:\n",
    "            self.feature_names = self.pipeline.named_steps['preprocessor'].get_feature_names_out()\n",
    "        except:\n",
    "            # Fallback if feature names not available\n",
    "            n_features = len(self.model.feature_importances_)\n",
    "            self.feature_names = [f'feature_{i}' for i in range(n_features)]\n",
    "        \n",
    "        print(\"‚úÖ Model training completed!\")\n",
    "        \n",
    "        return cv_mape_scores\n",
    "    \n",
    "    def evaluate_model(self):\n",
    "        \"\"\"\n",
    "        Evaluate Random Forest model on test set with MAPE as primary metric\n",
    "        \"\"\"\n",
    "        print(\"üìä Evaluating model performance...\")\n",
    "        \n",
    "        # Make predictions\n",
    "        y_pred = self.pipeline.predict(self.X_test)\n",
    "        \n",
    "        # Calculate MAPE (sklearn returns as decimal, convert to percentage)\n",
    "        mape = mean_absolute_percentage_error(self.y_test, y_pred) * 100\n",
    "        \n",
    "        # Calculate other metrics\n",
    "        r2 = r2_score(self.y_test, y_pred)\n",
    "        mse = mean_squared_error(self.y_test, y_pred)\n",
    "        rmse = np.sqrt(mse)\n",
    "        mae = mean_absolute_error(self.y_test, y_pred)\n",
    "        \n",
    "        print(f\"Test Set Performance:\")\n",
    "        print(f\"MAPE: {mape:.4f}% üéØ (Primary Metric)\")\n",
    "        print(f\"R¬≤ Score: {r2:.4f}\")\n",
    "        print(f\"RMSE: {rmse:.2f}\")\n",
    "        print(f\"MAE: {mae:.2f}\")\n",
    "        \n",
    "        # MAPE interpretation\n",
    "        if mape < 10:\n",
    "            print(\"üìà Excellent prediction accuracy (MAPE < 10%)\")\n",
    "        elif mape < 20:\n",
    "            print(\"üìä Good prediction accuracy (MAPE < 20%)\")\n",
    "        elif mape < 50:\n",
    "            print(\"‚ö†Ô∏è Reasonable prediction accuracy (MAPE < 50%)\")\n",
    "        else:\n",
    "            print(\"‚ùå Poor prediction accuracy (MAPE > 50%)\")\n",
    "        \n",
    "        return {\n",
    "            'mape': mape,\n",
    "            'r2': r2,\n",
    "            'rmse': rmse,\n",
    "            'mae': mae,\n",
    "            'predictions': y_pred\n",
    "        }\n",
    "    \n",
    "    def get_feature_importance(self, top_n=15):\n",
    "        \"\"\"\n",
    "        Extract and return feature importance\n",
    "        \"\"\"\n",
    "        if self.model is None:\n",
    "            print(\"Model not trained yet!\")\n",
    "            return None\n",
    "        \n",
    "        # Get feature importances\n",
    "        importances = self.model.feature_importances_\n",
    "        \n",
    "        # Create DataFrame\n",
    "        self.feature_importance_df = pd.DataFrame({\n",
    "            'feature': self.feature_names,\n",
    "            'importance': importances\n",
    "        }).sort_values('importance', ascending=False)\n",
    "        \n",
    "        print(f\"Top {top_n} Feature Importances:\")\n",
    "        print(self.feature_importance_df.head(top_n).round(4))\n",
    "        \n",
    "        return self.feature_importance_df\n",
    "    \n",
    "    def plot_feature_importance(self, top_n=15, figsize=(12, 8)):\n",
    "        \"\"\"\n",
    "        Plot feature importance\n",
    "        \"\"\"\n",
    "        if self.feature_importance_df is None:\n",
    "            self.get_feature_importance(top_n)\n",
    "        \n",
    "        plot_data = self.feature_importance_df.head(top_n)\n",
    "        \n",
    "        plt.figure(figsize=figsize)\n",
    "        \n",
    "        bars = plt.barh(range(len(plot_data)), plot_data['importance'], \n",
    "                       color=plt.cm.viridis(np.linspace(0, 1, len(plot_data))))\n",
    "        \n",
    "        plt.yticks(range(len(plot_data)), plot_data['feature'])\n",
    "        plt.xlabel('Feature Importance')\n",
    "        plt.title(f'Top {top_n} Feature Importances - Random Forest', \n",
    "                  fontsize=14, fontweight='bold')\n",
    "        plt.grid(True, alpha=0.3, axis='x')\n",
    "        \n",
    "        # Add values on bars\n",
    "        for i, (bar, importance) in enumerate(zip(bars, plot_data['importance'])):\n",
    "            width = bar.get_width()\n",
    "            plt.text(width + max(plot_data['importance']) * 0.01, \n",
    "                    bar.get_y() + bar.get_height()/2,\n",
    "                    f'{importance:.4f}', ha='left', va='center', fontsize=9)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    def predict(self, new_data):\n",
    "        \"\"\"\n",
    "        Make predictions on new data\n",
    "        \"\"\"\n",
    "        if self.pipeline is None:\n",
    "            print(\"Model not trained yet!\")\n",
    "            return None\n",
    "        \n",
    "        return self.pipeline.predict(new_data)\n",
    "\n",
    "print(\"‚úÖ RandomForestLossPredictor class defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09dd287",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and train the Random Forest model\n",
    "print(\"üöÄ RANDOM FOREST MODEL TRAINING\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Initialize predictor\n",
    "rf_predictor = RandomForestLossPredictor(\n",
    "    n_estimators=100,\n",
    "    max_depth=10, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Prepare data (reusing the dataset from earlier)\n",
    "X_train, X_test, y_train, y_test = rf_predictor.prepare_data(df_ml, 'estimated_loss')\n",
    "\n",
    "# Train model\n",
    "cv_scores = rf_predictor.train_model(cv_folds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3510e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "evaluation_results = rf_predictor.evaluate_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81bae525",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get and plot feature importance\n",
    "feature_importance = rf_predictor.get_feature_importance(top_n=15)\n",
    "rf_predictor.plot_feature_importance(top_n=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4a3854",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction visualization for Random Forest with MAPE focus\n",
    "def plot_rf_predictions(rf_predictor, sample_size=1000):\n",
    "    \"\"\"\n",
    "    Visualize Random Forest predictions with MAPE emphasis\n",
    "    \"\"\"\n",
    "    \n",
    "    y_test = rf_predictor.y_test\n",
    "    y_pred = rf_predictor.pipeline.predict(rf_predictor.X_test)\n",
    "    \n",
    "    # Sample for visualization if dataset is large\n",
    "    if len(y_test) > sample_size:\n",
    "        indices = np.random.choice(len(y_test), sample_size, replace=False)\n",
    "        y_test_sample = y_test.iloc[indices]\n",
    "        y_pred_sample = y_pred[indices]\n",
    "    else:\n",
    "        y_test_sample = y_test\n",
    "        y_pred_sample = y_pred\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "    \n",
    "    # 1. Actual vs Predicted\n",
    "    ax1 = axes[0]\n",
    "    ax1.scatter(y_test_sample, y_pred_sample, alpha=0.6, s=30, color='forestgreen')\n",
    "    \n",
    "    # Perfect prediction line\n",
    "    min_val = min(y_test_sample.min(), y_pred_sample.min())\n",
    "    max_val = max(y_test_sample.max(), y_pred_sample.max())\n",
    "    ax1.plot([min_val, max_val], [min_val, max_val], 'r--', lw=2, label='Perfect Prediction')\n",
    "    \n",
    "    ax1.set_xlabel('Actual Estimated Loss')\n",
    "    ax1.set_ylabel('Predicted Estimated Loss')\n",
    "    ax1.set_title('Random Forest: Actual vs Predicted', fontsize=14, fontweight='bold')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add MAPE score\n",
    "    mape = mean_absolute_percentage_error(y_test_sample, y_pred_sample) * 100\n",
    "    ax1.text(0.05, 0.95, f'MAPE = {mape:.2f}%', transform=ax1.transAxes, \n",
    "            bbox=dict(boxstyle='round', facecolor='lightgreen', alpha=0.8))\n",
    "    \n",
    "    # 2. Residuals plot\n",
    "    ax2 = axes[1]\n",
    "    residuals = y_test_sample - y_pred_sample\n",
    "    ax2.scatter(y_pred_sample, residuals, alpha=0.6, s=30, color='forestgreen')\n",
    "    ax2.axhline(y=0, color='r', linestyle='--', lw=2)\n",
    "    ax2.set_xlabel('Predicted Estimated Loss')\n",
    "    ax2.set_ylabel('Residuals')\n",
    "    ax2.set_title('Random Forest: Residuals Plot', fontsize=14, fontweight='bold')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 3. Percentage Error Distribution\n",
    "    ax3 = axes[2]\n",
    "    percentage_errors = np.abs((y_test_sample - y_pred_sample) / y_test_sample) * 100\n",
    "    # Remove any infinite values\n",
    "    percentage_errors = percentage_errors[np.isfinite(percentage_errors)]\n",
    "    \n",
    "    ax3.hist(percentage_errors, bins=30, alpha=0.7, color='forestgreen', edgecolor='black')\n",
    "    ax3.axvline(mape, color='red', linestyle='--', linewidth=2, label=f'Mean APE = {mape:.2f}%')\n",
    "    ax3.set_xlabel('Absolute Percentage Error (%)')\n",
    "    ax3.set_ylabel('Frequency')\n",
    "    ax3.set_title('Distribution of Absolute Percentage Errors', fontsize=14, fontweight='bold')\n",
    "    ax3.legend()\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return y_pred, residuals\n",
    "\n",
    "# Plot predictions with MAPE focus\n",
    "y_pred_rf, residuals_rf = plot_rf_predictions(rf_predictor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8257bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter tuning for Random Forest using MAPE\n",
    "def tune_random_forest(rf_predictor, cv_folds=3):\n",
    "    \"\"\"\n",
    "    Perform hyperparameter tuning for Random Forest using MAPE\n",
    "    \"\"\"\n",
    "    print(\"üîß Tuning Random Forest hyperparameters using MAPE...\")\n",
    "    \n",
    "    # Define parameter grid\n",
    "    param_grid = {\n",
    "        'regressor__n_estimators': [50, 100, 200],\n",
    "        'regressor__max_depth': [5, 10, 15, None],\n",
    "        'regressor__min_samples_split': [2, 5, 10],\n",
    "        'regressor__min_samples_leaf': [1, 2, 4]\n",
    "    }\n",
    "    \n",
    "    # Perform grid search with MAPE\n",
    "    grid_search = GridSearchCV(\n",
    "        rf_predictor.pipeline,\n",
    "        param_grid,\n",
    "        cv=cv_folds,\n",
    "        scoring=mape_scorer,  # Using MAPE scorer\n",
    "        n_jobs=-1,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    grid_search.fit(rf_predictor.X_train, rf_predictor.y_train)\n",
    "    \n",
    "    print(f\"\\\\n‚úÖ Best parameters:\")\n",
    "    for param, value in grid_search.best_params_.items():\n",
    "        print(f\"  {param}: {value}\")\n",
    "    \n",
    "    # Note: sklearn returns negative MAPE, so we convert to positive\n",
    "    best_cv_mape = -grid_search.best_score_\n",
    "    print(f\"\\\\nBest CV MAPE score: {best_cv_mape:.4f}%\")\n",
    "    \n",
    "    # Evaluate tuned model on test set\n",
    "    y_pred_tuned = grid_search.best_estimator_.predict(rf_predictor.X_test)\n",
    "    mape_tuned = mean_absolute_percentage_error(rf_predictor.y_test, y_pred_tuned)\n",
    "    \n",
    "    print(f\"Tuned model test MAPE: {mape_tuned:.4f}%\")\n",
    "    print(f\"Original model test MAPE: {evaluation_results['mape']:.4f}%\")\n",
    "    improvement = evaluation_results['mape'] - mape_tuned\n",
    "    print(f\"MAPE improvement: {improvement:.4f}% {'‚úÖ' if improvement > 0 else '‚ùå'}\")\n",
    "    \n",
    "    return grid_search.best_estimator_\n",
    "\n",
    "# Perform hyperparameter tuning\n",
    "tuned_rf_model = tune_random_forest(rf_predictor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94153e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Random Forest model and make predictions\n",
    "import joblib\n",
    "\n",
    "def save_rf_model(model, filepath='random_forest_estimated_loss.pkl'):\n",
    "    \"\"\"Save the Random Forest model\"\"\"\n",
    "    joblib.dump(model, filepath)\n",
    "    print(f\"‚úÖ Random Forest model saved to {filepath}\")\n",
    "\n",
    "def load_rf_model(filepath='random_forest_estimated_loss.pkl'):\n",
    "    \"\"\"Load a saved Random Forest model\"\"\"\n",
    "    return joblib.load(filepath)\n",
    "\n",
    "# Save the model\n",
    "save_rf_model(rf_predictor.pipeline, 'random_forest_estimated_loss.pkl')\n",
    "\n",
    "# Example predictions on new data\n",
    "print(\"\\\\nüîÆ RANDOM FOREST PREDICTIONS ON NEW DATA\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Create sample new data\n",
    "new_transactions = pd.DataFrame({\n",
    "    'transaction_amount': [200.0, 1500.0, 50.0, 3000.0],\n",
    "    'account_age_days': [45, 500, 10, 1000],\n",
    "    'previous_claims': [0, 2, 0, 5],\n",
    "    'risk_score': [20.0, 65.0, 15.0, 85.0],\n",
    "    'merchant_rating': [4.8, 3.2, 4.5, 2.0],\n",
    "    'transaction_type': ['purchase', 'transfer', 'purchase', 'withdrawal'],\n",
    "    'merchant_category': ['retail', 'travel', 'food', 'other'],\n",
    "    'user_tier': ['bronze', 'gold', 'bronze', 'platinum'],\n",
    "    'payment_method': ['credit_card', 'bank_transfer', 'debit_card', 'digital_wallet'],\n",
    "    'country': ['US', 'UK', 'CA', 'DE']\n",
    "})\n",
    "\n",
    "print(\"New transaction data:\")\n",
    "print(new_transactions)\n",
    "\n",
    "# Make predictions\n",
    "rf_predictions = rf_predictor.predict(new_transactions)\n",
    "\n",
    "print(f\"\\\\nRandom Forest Predicted estimated_loss values:\")\n",
    "for i, (idx, row) in enumerate(new_transactions.iterrows()):\n",
    "    print(f\"Transaction {i+1}: ${rf_predictions[i]:.2f}\")\n",
    "    print(f\"  - Amount: ${row['transaction_amount']:.2f}, Risk: {row['risk_score']:.1f}, Type: {row['transaction_type']}\")\n",
    "    \n",
    "print(f\"\\\\nAverage predicted loss: ${rf_predictions.mean():.2f}\")\n",
    "print(f\"Max predicted loss: ${rf_predictions.max():.2f}\")\n",
    "print(f\"Min predicted loss: ${rf_predictions.min():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8298fba8",
   "metadata": {},
   "source": [
    "## üå≤ Random Forest Quick Start Guide - MAPE Focused\n",
    "\n",
    "### Simple Usage with MAPE as Primary Metric:\n",
    "\n",
    "```python\n",
    "# 1. Initialize Random Forest predictor\n",
    "rf_predictor = RandomForestLossPredictor(\n",
    "    n_estimators=100,\n",
    "    max_depth=10,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 2. Prepare your data\n",
    "X_train, X_test, y_train, y_test = rf_predictor.prepare_data(\n",
    "    df, 'estimated_loss'  # your target column\n",
    ")\n",
    "\n",
    "# 3. Train the model with MAPE cross-validation\n",
    "cv_mape_scores = rf_predictor.train_model(cv_folds=5)\n",
    "\n",
    "# 4. Evaluate performance (MAPE is primary metric)\n",
    "results = rf_predictor.evaluate_model()\n",
    "\n",
    "# 5. Detailed MAPE analysis\n",
    "mape_analysis = analyze_mape_performance(rf_predictor)\n",
    "\n",
    "# 6. Get feature importance\n",
    "importance = rf_predictor.get_feature_importance()\n",
    "rf_predictor.plot_feature_importance()\n",
    "\n",
    "# 7. Make predictions\n",
    "predictions = rf_predictor.predict(new_data)\n",
    "```\n",
    "\n",
    "### Why MAPE is Perfect for estimated_loss:\n",
    "\n",
    "- ‚úÖ **Percentage-Based**: Easy to interpret (e.g., \"20% error\")\n",
    "- ‚úÖ **Scale-Independent**: Works for small and large loss amounts\n",
    "- ‚úÖ **Business-Friendly**: Management understands percentages\n",
    "- ‚úÖ **Relative Error**: More meaningful than absolute errors\n",
    "- ‚úÖ **Benchmark Standard**: Industry standard for forecasting accuracy\n",
    "\n",
    "### MAPE Interpretation Guidelines:\n",
    "- **< 10%**: Excellent prediction accuracy üìà\n",
    "- **10-20%**: Good prediction accuracy üìä  \n",
    "- **20-50%**: Fair prediction accuracy ‚ö†Ô∏è\n",
    "- **> 50%**: Poor prediction accuracy ‚ùå\n",
    "\n",
    "### MAPE Advantages for Financial Predictions:\n",
    "- **Risk Assessment**: Understand prediction uncertainty as %\n",
    "- **Portfolio Planning**: Compare accuracy across different loss ranges\n",
    "- **Resource Allocation**: Budget based on prediction confidence\n",
    "- **Model Comparison**: Easy to compare different models\n",
    "- **Stakeholder Communication**: Simple percentage format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a3e6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAPE Analysis and Interpretation\n",
    "def analyze_mape_performance(rf_predictor, threshold_percentages=[10, 20, 30]):\n",
    "    \"\"\"\n",
    "    Analyze MAPE performance in detail\n",
    "    \"\"\"\n",
    "    y_test = rf_predictor.y_test\n",
    "    y_pred = rf_predictor.pipeline.predict(rf_predictor.X_test)\n",
    "    \n",
    "    # Calculate individual percentage errors\n",
    "    percentage_errors = np.abs((y_test - y_pred) / y_test) * 100\n",
    "    percentage_errors = percentage_errors[np.isfinite(percentage_errors)]  # Remove any inf values\n",
    "    \n",
    "    print(\"üéØ DETAILED MAPE ANALYSIS\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Overall MAPE\n",
    "    overall_mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "    print(f\"Overall MAPE: {overall_mape:.2f}%\")\n",
    "    \n",
    "    # MAPE interpretation\n",
    "    if overall_mape < 10:\n",
    "        print(\"üìà EXCELLENT prediction accuracy!\")\n",
    "    elif overall_mape < 20:\n",
    "        print(\"üìä GOOD prediction accuracy\")\n",
    "    elif overall_mape < 30:\n",
    "        print(\"‚ö†Ô∏è FAIR prediction accuracy\")\n",
    "    else:\n",
    "        print(\"‚ùå POOR prediction accuracy - consider model improvements\")\n",
    "    \n",
    "    print(f\"\\nüìä Prediction Accuracy Distribution:\")\n",
    "    \n",
    "    # Analyze predictions within different error thresholds\n",
    "    for threshold in threshold_percentages:\n",
    "        within_threshold = (percentage_errors <= threshold).sum()\n",
    "        percentage_within = (within_threshold / len(percentage_errors)) * 100\n",
    "        print(f\"Within {threshold}% error: {within_threshold}/{len(percentage_errors)} predictions ({percentage_within:.1f}%)\")\n",
    "    \n",
    "    # Quartile analysis\n",
    "    print(f\"\\nüìà Error Distribution Quartiles:\")\n",
    "    print(f\"25th percentile: {np.percentile(percentage_errors, 25):.2f}%\")\n",
    "    print(f\"50th percentile (median): {np.percentile(percentage_errors, 50):.2f}%\")\n",
    "    print(f\"75th percentile: {np.percentile(percentage_errors, 75):.2f}%\")\n",
    "    print(f\"95th percentile: {np.percentile(percentage_errors, 95):.2f}%\")\n",
    "    \n",
    "    # Business impact analysis\n",
    "    print(f\"\\nüí∞ Business Impact Analysis:\")\n",
    "    total_actual_loss = y_test.sum()\n",
    "    total_predicted_loss = y_pred.sum()\n",
    "    total_error = abs(total_actual_loss - total_predicted_loss)\n",
    "    total_error_percentage = (total_error / total_actual_loss) * 100\n",
    "    \n",
    "    print(f\"Total Actual Loss: ${total_actual_loss:,.2f}\")\n",
    "    print(f\"Total Predicted Loss: ${total_predicted_loss:,.2f}\")\n",
    "    print(f\"Total Absolute Error: ${total_error:,.2f}\")\n",
    "    print(f\"Total Error Percentage: {total_error_percentage:.2f}%\")\n",
    "    \n",
    "    return {\n",
    "        'overall_mape': overall_mape,\n",
    "        'percentage_errors': percentage_errors,\n",
    "        'within_thresholds': {f'{t}%': (percentage_errors <= t).sum() for t in threshold_percentages}\n",
    "    }\n",
    "\n",
    "# Run detailed MAPE analysis\n",
    "mape_analysis = analyze_mape_performance(rf_predictor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5123a481",
   "metadata": {},
   "source": [
    "## üîç MAPE TROUBLESHOOTING & PIPELINE ANALYSIS\n",
    "\n",
    "### Common Causes of High MAPE Scores and Solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec25e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PIPELINE ANALYSIS: Identifying High MAPE Causes\n",
    "def diagnose_high_mape_issues(df, target_col='estimated_loss'):\n",
    "    \"\"\"\n",
    "    Diagnose potential causes of high MAPE scores in the pipeline\n",
    "    \"\"\"\n",
    "    print(\"üîç DIAGNOSING POTENTIAL HIGH MAPE CAUSES\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Issue 1: Zero or very small target values\n",
    "    print(\"1Ô∏è‚É£ ZERO/SMALL TARGET VALUE ANALYSIS:\")\n",
    "    zero_count = (df[target_col] == 0).sum()\n",
    "    small_values = (df[target_col] < 1).sum()\n",
    "    very_small_values = (df[target_col] < 0.1).sum()\n",
    "    \n",
    "    print(f\"   Zero values: {zero_count}/{len(df)} ({zero_count/len(df)*100:.2f}%)\")\n",
    "    print(f\"   Values < 1: {small_values}/{len(df)} ({small_values/len(df)*100:.2f}%)\")\n",
    "    print(f\"   Values < 0.1: {very_small_values}/{len(df)} ({very_small_values/len(df)*100:.2f}%)\")\n",
    "    \n",
    "    if zero_count > 0:\n",
    "        print(\"   ‚ö†Ô∏è  CRITICAL ISSUE: Zero values will cause infinite MAPE!\")\n",
    "    if small_values > len(df) * 0.1:\n",
    "        print(\"   ‚ö†Ô∏è  WARNING: Many small values will inflate MAPE significantly!\")\n",
    "    \n",
    "    # Issue 2: Target distribution analysis\n",
    "    print(f\"\\\\n2Ô∏è‚É£ TARGET DISTRIBUTION ANALYSIS:\")\n",
    "    print(f\"   Min: {df[target_col].min():.4f}\")\n",
    "    print(f\"   Max: {df[target_col].max():.4f}\")\n",
    "    print(f\"   Mean: {df[target_col].mean():.4f}\")\n",
    "    print(f\"   Median: {df[target_col].median():.4f}\")\n",
    "    print(f\"   Std: {df[target_col].std():.4f}\")\n",
    "    \n",
    "    # Check for high variance\n",
    "    cv = df[target_col].std() / df[target_col].mean()\n",
    "    print(f\"   Coefficient of Variation: {cv:.4f}\")\n",
    "    if cv > 1:\n",
    "        print(\"   ‚ö†Ô∏è  WARNING: High variance (CV > 1) makes prediction difficult!\")\n",
    "    \n",
    "    # Issue 3: Skewness analysis\n",
    "    from scipy.stats import skew\n",
    "    skewness = skew(df[target_col])\n",
    "    print(f\"   Skewness: {skewness:.4f}\")\n",
    "    if abs(skewness) > 2:\n",
    "        print(\"   ‚ö†Ô∏è  WARNING: Highly skewed data may need transformation!\")\n",
    "    \n",
    "    # Issue 4: Feature-target relationship strength\n",
    "    print(f\"\\\\n3Ô∏è‚É£ FEATURE-TARGET RELATIONSHIP ANALYSIS:\")\n",
    "    numerical_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    numerical_cols.remove(target_col)\n",
    "    \n",
    "    weak_correlations = 0\n",
    "    for col in numerical_cols:\n",
    "        corr = df[col].corr(df[target_col])\n",
    "        if abs(corr) < 0.1:\n",
    "            weak_correlations += 1\n",
    "    \n",
    "    print(f\"   Features with weak correlation (|r| < 0.1): {weak_correlations}/{len(numerical_cols)}\")\n",
    "    if weak_correlations > len(numerical_cols) * 0.5:\n",
    "        print(\"   ‚ö†Ô∏è  WARNING: Many features have weak relationships with target!\")\n",
    "    \n",
    "    # Issue 5: Data generation noise analysis\n",
    "    print(f\"\\\\n4Ô∏è‚É£ DATA GENERATION ISSUES:\")\n",
    "    # Check if data was generated with high noise\n",
    "    # Look at the data generation code pattern\n",
    "    print(\"   Checking synthetic data generation patterns...\")\n",
    "    \n",
    "    # Calculate signal-to-noise ratio estimate\n",
    "    # Assume base effects create signal, random noise creates noise\n",
    "    feature_effects_sum = (\n",
    "        df['risk_score'].mean() * 0.5 +  # Risk score effect\n",
    "        df['previous_claims'].mean() * 8 +  # Claims effect  \n",
    "        20  # Average categorical effects\n",
    "    )\n",
    "    noise_std = 15  # From data generation\n",
    "    snr = feature_effects_sum / noise_std\n",
    "    print(f\"   Estimated Signal-to-Noise Ratio: {snr:.2f}\")\n",
    "    if snr < 3:\n",
    "        print(\"   ‚ö†Ô∏è  WARNING: High noise relative to signal!\")\n",
    "    \n",
    "    # Issue 6: Model complexity vs data size\n",
    "    print(f\"\\\\n5Ô∏è‚É£ MODEL COMPLEXITY ANALYSIS:\")\n",
    "    n_samples = len(df)\n",
    "    n_features_est = len(numerical_cols) + 20  # Estimate with one-hot encoding\n",
    "    ratio = n_samples / n_features_est\n",
    "    print(f\"   Sample-to-feature ratio: {ratio:.1f}\")\n",
    "    if ratio < 10:\n",
    "        print(\"   ‚ö†Ô∏è  WARNING: Low sample-to-feature ratio may cause overfitting!\")\n",
    "    \n",
    "    return {\n",
    "        'zero_values': zero_count,\n",
    "        'small_values': small_values,\n",
    "        'cv': cv,\n",
    "        'skewness': skewness,\n",
    "        'weak_correlations': weak_correlations,\n",
    "        'snr': snr,\n",
    "        'sample_feature_ratio': ratio\n",
    "    }\n",
    "\n",
    "# Run diagnostic analysis\n",
    "diagnostic_results = diagnose_high_mape_issues(df_ml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6df75d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTIONS for High MAPE Issues\n",
    "def implement_mape_improvements(df, target_col='estimated_loss'):\n",
    "    \"\"\"\n",
    "    Implement solutions for common high MAPE causes\n",
    "    \"\"\"\n",
    "    print(\"üîß IMPLEMENTING MAPE IMPROVEMENT SOLUTIONS\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    df_improved = df.copy()\n",
    "    \n",
    "    # Solution 1: Handle zero/small values\n",
    "    print(\"1Ô∏è‚É£ HANDLING ZERO/SMALL VALUES:\")\n",
    "    original_zeros = (df_improved[target_col] == 0).sum()\n",
    "    original_small = (df_improved[target_col] < 1).sum()\n",
    "    \n",
    "    # Add small constant to avoid division by zero\n",
    "    min_threshold = 0.01\n",
    "    df_improved[f'{target_col}_adjusted'] = df_improved[target_col].apply(\n",
    "        lambda x: max(x, min_threshold)\n",
    "    )\n",
    "    \n",
    "    adjusted_zeros = (df_improved[f'{target_col}_adjusted'] == 0).sum()\n",
    "    print(f\"   Fixed zero values: {original_zeros} ‚Üí {adjusted_zeros}\")\n",
    "    print(f\"   Minimum value set to: {min_threshold}\")\n",
    "    \n",
    "    # Solution 2: Log transformation for skewed data\n",
    "    print(f\"\\\\n2Ô∏è‚É£ LOG TRANSFORMATION FOR SKEWED DATA:\")\n",
    "    from scipy.stats import skew\n",
    "    original_skew = skew(df_improved[target_col])\n",
    "    \n",
    "    # Apply log1p transformation (log(1+x) to handle zeros)\n",
    "    df_improved[f'{target_col}_log'] = np.log1p(df_improved[target_col])\n",
    "    log_skew = skew(df_improved[f'{target_col}_log'])\n",
    "    \n",
    "    print(f\"   Original skewness: {original_skew:.4f}\")\n",
    "    print(f\"   Log-transformed skewness: {log_skew:.4f}\")\n",
    "    print(f\"   Improvement: {abs(original_skew) - abs(log_skew):.4f}\")\n",
    "    \n",
    "    # Solution 3: Outlier handling\n",
    "    print(f\"\\\\n3Ô∏è‚É£ OUTLIER HANDLING:\")\n",
    "    Q1 = df_improved[target_col].quantile(0.25)\n",
    "    Q3 = df_improved[target_col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    \n",
    "    outliers = ((df_improved[target_col] < lower_bound) | \n",
    "                (df_improved[target_col] > upper_bound)).sum()\n",
    "    \n",
    "    # Cap outliers instead of removing them\n",
    "    df_improved[f'{target_col}_capped'] = df_improved[target_col].clip(\n",
    "        lower=max(lower_bound, 0), upper=upper_bound\n",
    "    )\n",
    "    \n",
    "    print(f\"   Outliers detected: {outliers}\")\n",
    "    print(f\"   Capping range: [{max(lower_bound, 0):.2f}, {upper_bound:.2f}]\")\n",
    "    \n",
    "    # Solution 4: Feature engineering for better signal\n",
    "    print(f\"\\\\n4Ô∏è‚É£ FEATURE ENGINEERING FOR BETTER SIGNAL:\")\n",
    "    \n",
    "    # Create interaction features\n",
    "    df_improved['amount_risk_interaction'] = (\n",
    "        df_improved['transaction_amount'] * df_improved['risk_score']\n",
    "    )\n",
    "    df_improved['claims_age_interaction'] = (\n",
    "        df_improved['previous_claims'] * (1 / (df_improved['account_age_days'] + 1))\n",
    "    )\n",
    "    \n",
    "    # Create binned features for non-linear patterns\n",
    "    df_improved['amount_bins'] = pd.qcut(df_improved['transaction_amount'], \n",
    "                                       q=5, labels=['very_low', 'low', 'medium', 'high', 'very_high'])\n",
    "    df_improved['risk_bins'] = pd.cut(df_improved['risk_score'], \n",
    "                                    bins=[0, 20, 40, 60, 80, 100], \n",
    "                                    labels=['very_low', 'low', 'medium', 'high', 'very_high'])\n",
    "    \n",
    "    print(f\"   Added interaction features: 2\")\n",
    "    print(f\"   Added binned features: 2\")\n",
    "    \n",
    "    # Solution 5: Robust scaling instead of standard scaling\n",
    "    print(f\"\\\\n5Ô∏è‚É£ ROBUST PREPROCESSING:\")\n",
    "    from sklearn.preprocessing import RobustScaler\n",
    "    \n",
    "    print(\"   Recommendation: Use RobustScaler instead of StandardScaler\")\n",
    "    print(\"   Reason: Less sensitive to outliers\")\n",
    "    \n",
    "    return df_improved\n",
    "\n",
    "# Apply improvements\n",
    "df_improved = implement_mape_improvements(df_ml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a3f69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPROVED RandomForestLossPredictor with MAPE optimizations\n",
    "class ImprovedRandomForestPredictor(RandomForestLossPredictor):\n",
    "    \"\"\"\n",
    "    Enhanced Random Forest predictor with MAPE-specific optimizations\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, n_estimators=100, max_depth=10, random_state=42, \n",
    "                 handle_zeros=True, use_robust_scaling=True, min_threshold=0.01):\n",
    "        super().__init__(n_estimators, max_depth, random_state)\n",
    "        self.handle_zeros = handle_zeros\n",
    "        self.use_robust_scaling = use_robust_scaling\n",
    "        self.min_threshold = min_threshold\n",
    "        \n",
    "    def prepare_data(self, df, target_col, test_size=0.2):\n",
    "        \"\"\"\n",
    "        Prepare data with MAPE-specific improvements\n",
    "        \"\"\"\n",
    "        print(\"üîÑ Preparing data with MAPE optimizations...\")\n",
    "        \n",
    "        df_prep = df.copy()\n",
    "        \n",
    "        # Handle zero/small values if enabled\n",
    "        if self.handle_zeros:\n",
    "            original_zeros = (df_prep[target_col] == 0).sum()\n",
    "            df_prep[target_col] = df_prep[target_col].apply(\n",
    "                lambda x: max(x, self.min_threshold)\n",
    "            )\n",
    "            if original_zeros > 0:\n",
    "                print(f\"   ‚úÖ Fixed {original_zeros} zero values (set minimum to {self.min_threshold})\")\n",
    "        \n",
    "        # Separate features and target\n",
    "        X = df_prep.drop(columns=[target_col])\n",
    "        y = df_prep[target_col]\n",
    "        \n",
    "        # Identify column types\n",
    "        numerical_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "        categorical_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "        \n",
    "        print(f\"Numerical features ({len(numerical_cols)}): {numerical_cols}\")\n",
    "        print(f\"Categorical features ({len(categorical_cols)}): {categorical_cols}\")\n",
    "        \n",
    "        # Choose scaler based on setting\n",
    "        if self.use_robust_scaling:\n",
    "            from sklearn.preprocessing import RobustScaler\n",
    "            numerical_transformer = RobustScaler()\n",
    "            print(\"   ‚úÖ Using RobustScaler (outlier-resistant)\")\n",
    "        else:\n",
    "            numerical_transformer = StandardScaler()\n",
    "            print(\"   Using StandardScaler\")\n",
    "        \n",
    "        # Create preprocessing pipeline\n",
    "        preprocessor = ColumnTransformer(\n",
    "            transformers=[\n",
    "                ('num', numerical_transformer, numerical_cols),\n",
    "                ('cat', OneHotEncoder(drop='first', sparse_output=False), categorical_cols)\n",
    "            ])\n",
    "        \n",
    "        # Split data\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=test_size, random_state=self.random_state\n",
    "        )\n",
    "        \n",
    "        print(f\"Training set: {X_train.shape[0]} samples\")\n",
    "        print(f\"Test set: {X_test.shape[0]} samples\")\n",
    "        \n",
    "        # Store for later use\n",
    "        self.X_train = X_train\n",
    "        self.X_test = X_test\n",
    "        self.y_train = y_train\n",
    "        self.y_test = y_test\n",
    "        self.preprocessor = preprocessor\n",
    "        self.numerical_cols = numerical_cols\n",
    "        self.categorical_cols = categorical_cols\n",
    "        \n",
    "        return X_train, X_test, y_train, y_test\n",
    "\n",
    "# Compare original vs improved approach\n",
    "print(\"üéØ COMPARING ORIGINAL vs IMPROVED APPROACH\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Test with improved predictor\n",
    "improved_predictor = ImprovedRandomForestPredictor(\n",
    "    n_estimators=100,\n",
    "    max_depth=10,\n",
    "    random_state=42,\n",
    "    handle_zeros=True,\n",
    "    use_robust_scaling=True,\n",
    "    min_threshold=0.01\n",
    ")\n",
    "\n",
    "print(\"\\\\nTesting with improved predictor configuration...\")\n",
    "print(\"Improvements enabled:\")\n",
    "print(\"  ‚úÖ Zero value handling\")\n",
    "print(\"  ‚úÖ Robust scaling\")\n",
    "print(\"  ‚úÖ Minimum threshold protection\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc9ceda",
   "metadata": {},
   "source": [
    "## üö® KEY ISSUES IDENTIFIED IN CURRENT PIPELINE\n",
    "\n",
    "Based on the analysis, here are the **primary causes of high MAPE scores** in the current pipeline:\n",
    "\n",
    "### 1. **Zero Values Problem** üî¥\n",
    "- **Issue**: The data generation can create `estimated_loss = 0` when `max(0, base_loss)` results in zero\n",
    "- **Impact**: Division by zero in MAPE calculation causes infinite errors\n",
    "- **Solution**: Set minimum threshold (e.g., 0.01) to avoid zeros\n",
    "\n",
    "### 2. **High Noise-to-Signal Ratio** üü°\n",
    "- **Issue**: Random noise of ¬±15 added to relatively small base effects\n",
    "- **Impact**: Makes predictions inherently difficult\n",
    "- **Solution**: Reduce noise or increase signal strength in data generation\n",
    "\n",
    "### 3. **Skewed Target Distribution** üü°\n",
    "- **Issue**: Log-normal transaction amounts and exponential account ages create skewed targets\n",
    "- **Impact**: MAPE is more sensitive to errors on small values\n",
    "- **Solution**: Consider log transformation or robust scaling\n",
    "\n",
    "### 4. **Small Target Values** üü†\n",
    "- **Issue**: Many target values are small (< 10), making percentage errors large\n",
    "- **Impact**: Small absolute errors become large percentage errors\n",
    "- **Solution**: Target value adjustment or different metric consideration\n",
    "\n",
    "### 5. **Feature Scaling Issues** üü°\n",
    "- **Issue**: StandardScaler is sensitive to outliers in transaction amounts\n",
    "- **Impact**: Poor feature representation affects model performance\n",
    "- **Solution**: Use RobustScaler instead\n",
    "\n",
    "### 6. **Model Hyperparameters** üü°\n",
    "- **Issue**: Default max_depth=10 might be too shallow for complex interactions\n",
    "- **Impact**: Underfitting leads to poor predictions\n",
    "- **Solution**: Tune hyperparameters specifically for MAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9e1706",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Trained Model to Test Set (Missing Target Column)\n",
    "print(\"üéØ APPLYING TRAINED MODEL TO NEW TEST SET\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "def apply_model_to_test_set(trained_model, test_df, model_type=\"standard\"):\n",
    "    \"\"\"\n",
    "    Apply a trained model to a test set that doesn't have the target column\n",
    "    \n",
    "    Parameters:\n",
    "    - trained_model: Your trained model object (RandomForestLossPredictor or LogTransformRandomForestPredictor)\n",
    "    - test_df: DataFrame with same schema as training data but missing target column\n",
    "    - model_type: \"standard\" or \"log_transform\" to handle inverse transformation\n",
    "    \n",
    "    Returns:\n",
    "    - predictions: Array of predictions\n",
    "    - prediction_df: DataFrame with original data + predictions\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"üìä Processing test set with {len(test_df)} samples...\")\n",
    "    print(f\"Model type: {model_type}\")\n",
    "    \n",
    "    # Validate that test_df has the expected columns\n",
    "    expected_features = set()\n",
    "    if hasattr(trained_model, 'numerical_cols') and hasattr(trained_model, 'categorical_cols'):\n",
    "        expected_features = set(trained_model.numerical_cols + trained_model.categorical_cols)\n",
    "    \n",
    "    test_features = set(test_df.columns)\n",
    "    \n",
    "    if expected_features:\n",
    "        missing_features = expected_features - test_features\n",
    "        extra_features = test_features - expected_features\n",
    "        \n",
    "        if missing_features:\n",
    "            print(f\"‚ö†Ô∏è  WARNING: Missing features in test set: {missing_features}\")\n",
    "        if extra_features:\n",
    "            print(f\"‚ÑπÔ∏è  Extra features in test set (will be ignored): {extra_features}\")\n",
    "            # Keep only the expected features\n",
    "            test_df = test_df[list(expected_features)]\n",
    "    \n",
    "    print(f\"‚úÖ Test set shape after validation: {test_df.shape}\")\n",
    "    \n",
    "    # Make predictions\n",
    "    try:\n",
    "        if model_type == \"log_transform\" and hasattr(trained_model, 'use_log_transform'):\n",
    "            # For log transform models, the predict method handles inverse transformation automatically\n",
    "            predictions = trained_model.predict(test_df)\n",
    "            print(\"‚úÖ Applied log-transform model with automatic inverse transformation\")\n",
    "        else:\n",
    "            # For standard models\n",
    "            predictions = trained_model.predict(test_df)\n",
    "            print(\"‚úÖ Applied standard model\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error making predictions: {e}\")\n",
    "        return None, None\n",
    "    \n",
    "    # Create results DataFrame\n",
    "    result_df = test_df.copy()\n",
    "    result_df['predicted_estimated_loss'] = predictions\n",
    "    \n",
    "    # Add prediction statistics\n",
    "    print(f\"\\nüìà PREDICTION SUMMARY:\")\n",
    "    print(f\"Number of predictions: {len(predictions)}\")\n",
    "    print(f\"Mean predicted loss: ${predictions.mean():.2f}\")\n",
    "    print(f\"Median predicted loss: ${np.median(predictions):.2f}\")\n",
    "    print(f\"Min predicted loss: ${predictions.min():.2f}\")\n",
    "    print(f\"Max predicted loss: ${predictions.max():.2f}\")\n",
    "    print(f\"Std deviation: ${predictions.std():.2f}\")\n",
    "    \n",
    "    # Prediction distribution\n",
    "    print(f\"\\nüìä PREDICTION DISTRIBUTION:\")\n",
    "    percentiles = [10, 25, 50, 75, 90, 95, 99]\n",
    "    for p in percentiles:\n",
    "        value = np.percentile(predictions, p)\n",
    "        print(f\"{p}th percentile: ${value:.2f}\")\n",
    "    \n",
    "    return predictions, result_df\n",
    "\n",
    "# Example usage function\n",
    "def demo_test_set_application():\n",
    "    \"\"\"\n",
    "    Demonstrate how to apply models to test sets\n",
    "    \"\"\"\n",
    "    print(\"\\nüéØ DEMONSTRATION: Creating sample test set and applying model\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # First, let's assume you have a trained model (you'll replace this with your actual trained model)\n",
    "    print(\"üìù Step 1: Load or reference your trained model\")\n",
    "    print(\"   # Replace 'your_trained_model' with your actual model variable\")\n",
    "    print(\"   # Examples:\")\n",
    "    print(\"   # - rf_predictor (if you used RandomForestLossPredictor)\")\n",
    "    print(\"   # - log_rf_predictor (if you used LogTransformRandomForestPredictor)\")\n",
    "    print(\"   # - improved_predictor (if you used ImprovedRandomForestPredictor)\")\n",
    "    \n",
    "    # Create sample test data (you'll replace this with your actual test data)\n",
    "    print(\"\\\\nüìù Step 2: Load your test set\")\n",
    "    print(\"   # Replace this with loading your actual test data:\")\n",
    "    print(\"   # test_data = pd.read_csv('your_test_file.csv')\")\n",
    "    print(\"   # OR\")\n",
    "    print(\"   # test_data = your_existing_test_dataframe\")\n",
    "    \n",
    "    # For demonstration, create sample test data with same structure as training data\n",
    "    sample_test_data = pd.DataFrame({\n",
    "        'transaction_amount': [150.0, 2500.0, 75.0, 1200.0, 500.0],\n",
    "        'account_age_days': [30, 365, 1200, 180, 90],\n",
    "        'previous_claims': [0, 3, 1, 2, 0],\n",
    "        'risk_score': [25.5, 75.2, 15.8, 45.0, 30.0],\n",
    "        'merchant_rating': [4.5, 2.1, 4.8, 3.5, 4.0],\n",
    "        'transaction_type': ['purchase', 'transfer', 'purchase', 'withdrawal', 'purchase'],\n",
    "        'merchant_category': ['retail', 'travel', 'food', 'other', 'retail'],\n",
    "        'user_tier': ['bronze', 'gold', 'silver', 'silver', 'bronze'],\n",
    "        'payment_method': ['credit_card', 'bank_transfer', 'debit_card', 'digital_wallet', 'credit_card'],\n",
    "        'country': ['US', 'UK', 'CA', 'DE', 'US']\n",
    "    })\n",
    "    \n",
    "    print(f\"\\\\nüìä Sample test data:\")\n",
    "    print(sample_test_data)\n",
    "    \n",
    "    print(f\"\\\\nüìù Step 3: Apply model to test set\")\n",
    "    print(\"   # Use the apply_model_to_test_set function:\")\n",
    "    print(\"   # predictions, results_df = apply_model_to_test_set(\")\n",
    "    print(\"   #     trained_model=your_trained_model,\")\n",
    "    print(\"   #     test_df=test_data,\")\n",
    "    print(\"   #     model_type='standard'  # or 'log_transform' if using log model\")\n",
    "    print(\"   # )\")\n",
    "    \n",
    "    return sample_test_data\n",
    "\n",
    "# Run demonstration\n",
    "sample_test_data = demo_test_set_application()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776a392e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PRACTICAL EXAMPLE: Apply Your Trained Model to Real Test Set\n",
    "print(\"üöÄ PRACTICAL EXAMPLE: APPLYING YOUR TRAINED MODEL\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# STEP 1: Ensure you have a trained model\n",
    "print(\"üìã STEP 1: Train a model first (if not already done)\")\n",
    "print(\"You need to run one of these training approaches first:\")\n",
    "print(\"  Option A: Standard RandomForestLossPredictor\")\n",
    "print(\"  Option B: LogTransformRandomForestPredictor\") \n",
    "print(\"  Option C: ImprovedRandomForestPredictor\")\n",
    "\n",
    "# Example of how to train quickly if needed:\n",
    "def quick_train_model_for_testing():\n",
    "    \"\"\"\n",
    "    Quick training function for demonstration\n",
    "    \"\"\"\n",
    "    # Generate sample training data if df_ml doesn't exist\n",
    "    if 'df_ml' not in globals():\n",
    "        print(\"‚ö†Ô∏è  No training data found. Generating sample data...\")\n",
    "        \n",
    "        # Create sample training data\n",
    "        np.random.seed(42)\n",
    "        n_samples = 1000\n",
    "        \n",
    "        df_sample = pd.DataFrame({\n",
    "            'transaction_amount': np.random.exponential(100, n_samples),\n",
    "            'account_age_days': np.random.randint(1, 2000, n_samples),\n",
    "            'previous_claims': np.random.poisson(1.5, n_samples),\n",
    "            'risk_score': np.random.normal(50, 20, n_samples),\n",
    "            'merchant_rating': np.random.uniform(1, 5, n_samples),\n",
    "            'transaction_type': np.random.choice(['purchase', 'transfer', 'withdrawal'], n_samples),\n",
    "            'merchant_category': np.random.choice(['retail', 'travel', 'food', 'other'], n_samples),\n",
    "            'user_tier': np.random.choice(['bronze', 'silver', 'gold', 'platinum'], n_samples),\n",
    "            'payment_method': np.random.choice(['credit_card', 'debit_card', 'bank_transfer', 'digital_wallet'], n_samples),\n",
    "            'country': np.random.choice(['US', 'UK', 'CA', 'DE', 'FR'], n_samples)\n",
    "        })\n",
    "        \n",
    "        # Generate target variable\n",
    "        base_loss = (df_sample['transaction_amount'] * 0.02 + \n",
    "                    df_sample['risk_score'] * 0.5 + \n",
    "                    df_sample['previous_claims'] * 5 + \n",
    "                    np.random.normal(0, 15, n_samples))\n",
    "        df_sample['estimated_loss'] = np.maximum(0, base_loss)\n",
    "        \n",
    "        return df_sample\n",
    "    else:\n",
    "        return df_ml\n",
    "\n",
    "# STEP 2: Load your actual test data\n",
    "print(\"\\\\nüìã STEP 2: Load your test data\")\n",
    "print(\"Replace this section with your actual test data loading:\")\n",
    "\n",
    "def load_test_data():\n",
    "    \"\"\"\n",
    "    Load your test data here\n",
    "    \"\"\"\n",
    "    # REPLACE THIS WITH YOUR ACTUAL TEST DATA LOADING:\n",
    "    # return pd.read_csv('your_test_file.csv')\n",
    "    # OR\n",
    "    # return your_test_dataframe\n",
    "    \n",
    "    # For demonstration, create sample test data:\n",
    "    print(\"üìù Creating sample test data (replace with your actual data loading)\")\n",
    "    \n",
    "    test_data = pd.DataFrame({\n",
    "        'transaction_amount': [200.0, 1500.0, 50.0, 3000.0, 800.0, 120.0],\n",
    "        'account_age_days': [45, 500, 10, 1000, 200, 60],\n",
    "        'previous_claims': [0, 2, 0, 5, 1, 0],\n",
    "        'risk_score': [20.0, 65.0, 15.0, 85.0, 40.0, 25.0],\n",
    "        'merchant_rating': [4.8, 3.2, 4.5, 2.0, 3.8, 4.2],\n",
    "        'transaction_type': ['purchase', 'transfer', 'purchase', 'withdrawal', 'purchase', 'purchase'],\n",
    "        'merchant_category': ['retail', 'travel', 'food', 'other', 'retail', 'food'],\n",
    "        'user_tier': ['bronze', 'gold', 'bronze', 'platinum', 'silver', 'bronze'],\n",
    "        'payment_method': ['credit_card', 'bank_transfer', 'debit_card', 'digital_wallet', 'credit_card', 'debit_card'],\n",
    "        'country': ['US', 'UK', 'CA', 'DE', 'US', 'CA']\n",
    "    })\n",
    "    \n",
    "    print(f\"‚úÖ Test data loaded: {test_data.shape[0]} samples, {test_data.shape[1]} features\")\n",
    "    print(\"\\\\nTest data preview:\")\n",
    "    print(test_data.head())\n",
    "    \n",
    "    return test_data\n",
    "\n",
    "# Execute the steps\n",
    "print(\"\\\\nüîÑ EXECUTING STEPS...\")\n",
    "\n",
    "# Load training data and train a quick model\n",
    "training_data = quick_train_model_for_testing()\n",
    "print(f\"Training data: {training_data.shape}\")\n",
    "\n",
    "# Load test data\n",
    "test_data = load_test_data()\n",
    "\n",
    "print(\"\\\\n‚úÖ Ready to apply model to test set!\")\n",
    "print(\"\\\\nNext steps:\")\n",
    "print(\"1. Train your preferred model on the training data\")\n",
    "print(\"2. Use apply_model_to_test_set() function to get predictions\")\n",
    "print(\"3. Save or export the results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd89c47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPLETE WORKFLOW: Train Model & Apply to Test Set\n",
    "print(\"üéØ COMPLETE WORKFLOW: TRAIN MODEL & APPLY TO TEST SET\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "def complete_model_application_workflow():\n",
    "    \"\"\"\n",
    "    Complete end-to-end workflow for training and applying model to test set\n",
    "    \"\"\"\n",
    "    \n",
    "    # Step 1: Prepare training data\n",
    "    print(\"1Ô∏è‚É£ PREPARING TRAINING DATA\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    # Use existing data or create sample data\n",
    "    if 'df_ml' in globals() and len(df_ml) > 0:\n",
    "        training_df = df_ml.copy()\n",
    "        print(f\"‚úÖ Using existing training data: {training_df.shape}\")\n",
    "    else:\n",
    "        print(\"üìù Creating sample training data...\")\n",
    "        np.random.seed(42)\n",
    "        n_samples = 1000\n",
    "        \n",
    "        training_df = pd.DataFrame({\n",
    "            'transaction_amount': np.random.exponential(100, n_samples),\n",
    "            'account_age_days': np.random.randint(1, 2000, n_samples),\n",
    "            'previous_claims': np.random.poisson(1.5, n_samples),\n",
    "            'risk_score': np.random.normal(50, 20, n_samples).clip(0, 100),\n",
    "            'merchant_rating': np.random.uniform(1, 5, n_samples),\n",
    "            'transaction_type': np.random.choice(['purchase', 'transfer', 'withdrawal'], n_samples),\n",
    "            'merchant_category': np.random.choice(['retail', 'travel', 'food', 'other'], n_samples),\n",
    "            'user_tier': np.random.choice(['bronze', 'silver', 'gold', 'platinum'], n_samples),\n",
    "            'payment_method': np.random.choice(['credit_card', 'debit_card', 'bank_transfer', 'digital_wallet'], n_samples),\n",
    "            'country': np.random.choice(['US', 'UK', 'CA', 'DE', 'FR'], n_samples)\n",
    "        })\n",
    "        \n",
    "        # Generate realistic target variable\n",
    "        base_loss = (training_df['transaction_amount'] * 0.02 + \n",
    "                    training_df['risk_score'] * 0.5 + \n",
    "                    training_df['previous_claims'] * 10 + \n",
    "                    np.random.normal(0, 20, n_samples))\n",
    "        training_df['estimated_loss'] = np.maximum(0.01, base_loss)  # Avoid zeros\n",
    "        \n",
    "        print(f\"‚úÖ Created training data: {training_df.shape}\")\n",
    "    \n",
    "    # Step 2: Train the model\n",
    "    print(\"\\\\n2Ô∏è‚É£ TRAINING MODEL\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    # Train a log-transform model for better performance\n",
    "    model = LogTransformRandomForestPredictor(\n",
    "        n_estimators=100,\n",
    "        max_depth=15,\n",
    "        random_state=42,\n",
    "        use_log_transform=True\n",
    "    )\n",
    "    \n",
    "    # Prepare and train\n",
    "    model.prepare_data(training_df, 'estimated_loss', test_size=0.2)\n",
    "    cv_scores = model.train_model(cv_folds=3)\n",
    "    results = model.evaluate_model()\n",
    "    \n",
    "    print(f\"‚úÖ Model trained! MAPE: {results['mape']:.2f}%\")\n",
    "    \n",
    "    # Step 3: Create test data (replace this with your actual test data loading)\n",
    "    print(\"\\\\n3Ô∏è‚É£ LOADING TEST DATA\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    # REPLACE THIS SECTION WITH YOUR ACTUAL TEST DATA:\n",
    "    # test_df = pd.read_csv('your_test_file.csv')\n",
    "    \n",
    "    # For demonstration, create sample test data\n",
    "    test_df = pd.DataFrame({\n",
    "        'transaction_amount': [250.0, 1800.0, 95.0, 3500.0, 600.0, 150.0, 2200.0],\n",
    "        'account_age_days': [60, 400, 15, 900, 180, 45, 600],\n",
    "        'previous_claims': [1, 3, 0, 4, 2, 0, 1],\n",
    "        'risk_score': [30.0, 70.0, 20.0, 80.0, 45.0, 25.0, 60.0],\n",
    "        'merchant_rating': [4.2, 2.8, 4.6, 1.8, 3.5, 4.4, 3.0],\n",
    "        'transaction_type': ['purchase', 'transfer', 'purchase', 'withdrawal', 'purchase', 'purchase', 'transfer'],\n",
    "        'merchant_category': ['retail', 'travel', 'food', 'other', 'retail', 'food', 'travel'],\n",
    "        'user_tier': ['silver', 'gold', 'bronze', 'platinum', 'silver', 'bronze', 'gold'],\n",
    "        'payment_method': ['credit_card', 'bank_transfer', 'debit_card', 'digital_wallet', 'credit_card', 'debit_card', 'bank_transfer'],\n",
    "        'country': ['US', 'UK', 'CA', 'DE', 'US', 'CA', 'UK']\n",
    "    })\n",
    "    \n",
    "    print(f\"‚úÖ Test data loaded: {test_df.shape}\")\n",
    "    print(\"\\\\nTest data preview:\")\n",
    "    print(test_df.head(3))\n",
    "    \n",
    "    # Step 4: Apply model to test set\n",
    "    print(\"\\\\n4Ô∏è‚É£ APPLYING MODEL TO TEST SET\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    predictions, results_df = apply_model_to_test_set(\n",
    "        trained_model=model,\n",
    "        test_df=test_df,\n",
    "        model_type=\"log_transform\"\n",
    "    )\n",
    "    \n",
    "    # Step 5: Display and save results\n",
    "    print(\"\\\\n5Ô∏è‚É£ RESULTS\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    print(\"\\\\nüìä FINAL RESULTS:\")\n",
    "    print(results_df[['transaction_amount', 'risk_score', 'transaction_type', 'predicted_estimated_loss']].round(2))\n",
    "    \n",
    "    # Risk categorization\n",
    "    print(\"\\\\nüéØ RISK CATEGORIZATION:\")\n",
    "    results_df['risk_category'] = pd.cut(\n",
    "        results_df['predicted_estimated_loss'], \n",
    "        bins=[0, 10, 50, 100, float('inf')], \n",
    "        labels=['Low', 'Medium', 'High', 'Very High']\n",
    "    )\n",
    "    \n",
    "    risk_summary = results_df['risk_category'].value_counts()\n",
    "    print(risk_summary)\n",
    "    \n",
    "    # Save results (optional)\n",
    "    print(\"\\\\nüíæ SAVING RESULTS:\")\n",
    "    output_filename = f\"predicted_losses_{pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')}.csv\"\n",
    "    results_df.to_csv(output_filename, index=False)\n",
    "    print(f\"‚úÖ Results saved to: {output_filename}\")\n",
    "    \n",
    "    return model, test_df, predictions, results_df\n",
    "\n",
    "# Execute the complete workflow\n",
    "print(\"\\\\nüöÄ EXECUTING COMPLETE WORKFLOW...\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "try:\n",
    "    trained_model, test_data, predictions, final_results = complete_model_application_workflow()\n",
    "    print(\"\\\\nüéâ WORKFLOW COMPLETED SUCCESSFULLY!\")\n",
    "    print(f\"   - Trained model: ‚úÖ\")\n",
    "    print(f\"   - Test predictions: ‚úÖ ({len(predictions)} predictions)\")\n",
    "    print(f\"   - Results saved: ‚úÖ\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error in workflow: {e}\")\n",
    "    print(\"Please check your data and try again.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715c9b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SIMPLE SOLUTION: Apply Your Trained Model to Test Set\n",
    "print(\"üéØ SIMPLE SOLUTION: APPLY YOUR TRAINED MODEL TO TEST SET\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# STEP 1: Load your test data\n",
    "print(\"1Ô∏è‚É£ LOAD YOUR TEST DATA:\")\n",
    "print(\"Replace the next line with your actual test data loading:\")\n",
    "# test_df = pd.read_csv('your_test_file.csv')  # REPLACE WITH YOUR FILE\n",
    "\n",
    "# For demonstration - replace this with your actual test data:\n",
    "your_test_data = pd.DataFrame({\n",
    "    'transaction_amount': [100.0, 500.0, 1200.0, 75.0],\n",
    "    'account_age_days': [30, 200, 800, 15],\n",
    "    'previous_claims': [0, 1, 3, 0],\n",
    "    'risk_score': [25.0, 45.0, 75.0, 20.0],\n",
    "    'merchant_rating': [4.5, 3.8, 2.2, 4.8],\n",
    "    'transaction_type': ['purchase', 'transfer', 'withdrawal', 'purchase'],\n",
    "    'merchant_category': ['retail', 'travel', 'other', 'food'],\n",
    "    'user_tier': ['bronze', 'silver', 'gold', 'bronze'],\n",
    "    'payment_method': ['credit_card', 'bank_transfer', 'digital_wallet', 'debit_card'],\n",
    "    'country': ['US', 'UK', 'DE', 'CA']\n",
    "})\n",
    "\n",
    "print(f\"‚úÖ Test data shape: {your_test_data.shape}\")\n",
    "print(\"Test data preview:\")\n",
    "print(your_test_data)\n",
    "\n",
    "# STEP 2: Apply your trained model\n",
    "print(\"\\\\n2Ô∏è‚É£ APPLY YOUR TRAINED MODEL:\")\n",
    "print(\"Replace 'your_trained_model' with your actual trained model variable name\")\n",
    "\n",
    "# OPTION A: If you have a standard RandomForestLossPredictor\n",
    "if 'rf_predictor' in locals():\n",
    "    predictions = rf_predictor.predict(your_test_data)\n",
    "    print(\"‚úÖ Used rf_predictor model\")\n",
    "    \n",
    "# OPTION B: If you have a LogTransformRandomForestPredictor  \n",
    "elif 'log_rf_predictor' in locals():\n",
    "    predictions = log_rf_predictor.predict(your_test_data)\n",
    "    print(\"‚úÖ Used log_rf_predictor model (with automatic inverse transform)\")\n",
    "    \n",
    "# OPTION C: If you have an ImprovedRandomForestPredictor\n",
    "elif 'improved_predictor' in locals():\n",
    "    predictions = improved_predictor.predict(your_test_data)\n",
    "    print(\"‚úÖ Used improved_predictor model\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No trained model found in memory.\")\n",
    "    print(\"Please run one of the training cells first, or replace this with:\")\n",
    "    print(\"   predictions = your_trained_model.predict(your_test_data)\")\n",
    "    \n",
    "    # Create dummy predictions for demonstration\n",
    "    predictions = np.array([15.5, 45.2, 125.8, 8.3])\n",
    "    print(\"üîß Using dummy predictions for demonstration\")\n",
    "\n",
    "# STEP 3: Create results DataFrame\n",
    "print(f\"\\\\n3Ô∏è‚É£ CREATE RESULTS:\")\n",
    "results = your_test_data.copy()\n",
    "results['predicted_estimated_loss'] = predictions\n",
    "\n",
    "print(\"\\\\nüìä FINAL RESULTS:\")\n",
    "print(results[['transaction_amount', 'risk_score', 'predicted_estimated_loss']].round(2))\n",
    "\n",
    "# STEP 4: Save results\n",
    "print(\"\\\\n4Ô∏è‚É£ SAVE RESULTS:\")\n",
    "output_file = 'test_set_predictions.csv'\n",
    "results.to_csv(output_file, index=False)\n",
    "print(f\"‚úÖ Results saved to: {output_file}\")\n",
    "\n",
    "# STEP 5: Quick analysis\n",
    "print(\"\\\\n5Ô∏è‚É£ QUICK ANALYSIS:\")\n",
    "print(f\"Total predictions: {len(predictions)}\")\n",
    "print(f\"Average predicted loss: ${predictions.mean():.2f}\")\n",
    "print(f\"Highest risk transaction: ${predictions.max():.2f}\")\n",
    "print(f\"Lowest risk transaction: ${predictions.min():.2f}\")\n",
    "\n",
    "# Risk levels\n",
    "high_risk = (predictions > predictions.mean() + predictions.std()).sum()\n",
    "low_risk = (predictions < predictions.mean() - predictions.std()).sum()\n",
    "print(f\"High risk transactions: {high_risk}\")\n",
    "print(f\"Low risk transactions: {low_risk}\")\n",
    "\n",
    "print(\"\\\\n‚úÖ COMPLETE! Your test set predictions are ready.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
